{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ac2bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/storage1/shourovj/shourovj_works/Auburn/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import scipy.io as sio\n",
    "import sentencepiece\n",
    "import tiktoken\n",
    "import einops\n",
    "import wandb\n",
    "import accelerate\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29292507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'label'])\n"
     ]
    }
   ],
   "source": [
    "data = sio.loadmat('toy_data/label.mat')\n",
    "print(data.keys())\n",
    "labels = data['label']\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5ea87969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install matplotlib \n",
    "# !uv pip install seaborn \n",
    "# !uv pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299756fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f21df824",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"toy_data/\"\n",
    "all_files = glob(data_dir +'*.mat')\n",
    "# print((all_files))\n",
    "\n",
    "label_file = [file_name if file_name.split('.')[0].split('/')[-1] == 'label' else None for file_name in all_files ]\n",
    "label_file = [file_name for file_name in label_file if file_name is not None]\n",
    "\n",
    "# label_file\n",
    "\n",
    "\n",
    "feature_file = [file_name if file_name.split('.')[0].split('_')[-1] == 'feature' else None for file_name in all_files ]\n",
    "feature_file = [file_name for file_name in feature_file if file_name is not None]\n",
    "sorted_feature_file = sorted(feature_file, key=lambda x: int(x.split('.')[0].split('_')[2]))\n",
    "# print(sorted_feature_file)\n",
    "\n",
    "# len(feature_file)\n",
    "\n",
    "cluster_file = [file_name if file_name.split('.')[0].split('_')[-1] == 'index' else None for file_name in all_files ]\n",
    "cluster_file = [file_name for file_name in cluster_file if file_name is not None]\n",
    "sorted_cluster_file = sorted(cluster_file, key=lambda x: int(x.split('.')[0].split('_')[2]))\n",
    "# print(sorted_cluster_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d48fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531011f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame using dictionary - each key becomes a column\n",
    "# sorted_feature_file and sorted_cluster_file are lists of file paths (500 elements each)\n",
    "# labels is a numpy array of shape (500, 1), so we flatten it to (500,)\n",
    "df = pd.DataFrame({\n",
    "    'feature_file': sorted_feature_file,\n",
    "    'cluster_file': sorted_cluster_file,\n",
    "    'label': labels.flatten()  # Flatten from (500, 1) to (500,)\n",
    "})\n",
    "# len(df)\n",
    "# df.to_csv('data.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb8ae3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# df = pd.read_csv('toy_data/split/data.csv')\n",
    "# print(f\"Original dataset: {len(df)} samples\")\n",
    "# # df['feature'] = df['feature'].apply(lambda x: x.split('/')[-1])\n",
    "# df['feature'] = df['feature'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "# df.to_csv('data_split/data.csv', index=False)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a961866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "237b384c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: 500 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:08<00:00, 56.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 2 different shapes:\n",
      "  Shape (399, 1632): 14 files\n",
      "NON-STANDARD! First 5 files:\n",
      "      - Row 3: s_4_feature.mat\n",
      "      - Row 5: s_6_feature.mat\n",
      "      - Row 172: s_173_feature.mat\n",
      "      - Row 174: s_175_feature.mat\n",
      "      - Row 210: s_211_feature.mat\n",
      "  Shape (400, 1632): 486 files\n",
      "           feature                cluster  label\n",
      "0  s_1_feature.mat  s_1_cluster_index.mat      2\n",
      "1  s_2_feature.mat  s_2_cluster_index.mat      2\n",
      "2  s_3_feature.mat  s_3_cluster_index.mat      2\n",
      "3  s_4_feature.mat  s_4_cluster_index.mat      1\n",
      "4  s_5_feature.mat  s_5_cluster_index.mat      2\n",
      "           feature                cluster  label\n",
      "0  s_1_feature.mat  s_1_cluster_index.mat      2\n",
      "1  s_2_feature.mat  s_2_cluster_index.mat      2\n",
      "2  s_3_feature.mat  s_3_cluster_index.mat      2\n",
      "3  s_5_feature.mat  s_5_cluster_index.mat      2\n",
      "4  s_7_feature.mat  s_7_cluster_index.mat      1\n",
      "Cleaned dataset: 486 samples (removed 14 files)\n",
      "Original: 500 â†’ Cleaned: 486\n",
      "Train set: 340 samples (70.0%)\n",
      "Validation set: 73 samples (15.0%)\n",
      "Test set: 73 samples (15.0%)\n",
      "\n",
      "Train label distribution:\n",
      "label\n",
      "1    171\n",
      "2    169\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Val label distribution:\n",
      "label\n",
      "1    37\n",
      "2    36\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test label distribution:\n",
      "label\n",
      "1    37\n",
      "2    36\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ’¾ Problematic files saved to 'toy_data/split/problematic_files.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # Step 1: Load the original dataframe\n",
    "# data_dir = './toy_data/'\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# df = pd.read_csv('data_split/data.csv')\n",
    "# print(f\"Original dataset: {len(df)} samples\")\n",
    "\n",
    "\n",
    "# shape_dict = {}\n",
    "# problematic_indices = []\n",
    "# expected_shape = (400, 1632)\n",
    "\n",
    "# for idx in tqdm(range(len(df))):\n",
    "#     row = df.iloc[idx]\n",
    "#     feature_file = data_dir + row['feature']\n",
    "    \n",
    "#     try:\n",
    "#         f_data = sio.loadmat(feature_file)\n",
    "#         f_mat = f_data['feature_mat']\n",
    "#         shape = f_mat.shape\n",
    "        \n",
    "#         if shape not in shape_dict:\n",
    "#             shape_dict[shape] = []\n",
    "#         shape_dict[shape].append(idx)\n",
    "        \n",
    "#         # Check if shape doesn't match expected\n",
    "#         if shape[0] != expected_shape[0]:\n",
    "#             problematic_indices.append(idx)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error loading {feature_file}: {e}\")\n",
    "#         problematic_indices.append(idx)\n",
    "\n",
    "# print(f\"\\nFound {len(shape_dict)} different shapes:\")\n",
    "# for shape, indices in sorted(shape_dict.items()):\n",
    "#     print(f\"  Shape {shape}: {len(indices)} files\")\n",
    "#     if shape[0] != expected_shape[0]:\n",
    "#         print(f\"NON-STANDARD! First 5 files:\")\n",
    "#         for i in indices[:5]:\n",
    "#             print(f\"      - Row {i}: {df.iloc[i]['feature']}\")\n",
    "\n",
    "# # print(f\"FILTERING OUT {len(problematic_indices)} PROBLEMATIC FILES...\")\n",
    "\n",
    "# df_clean = df.drop(index=problematic_indices).reset_index(drop=True)\n",
    "# print(df.head())\n",
    "# print(df_clean.head())\n",
    "# df_clean.to_csv('data_split/data_clean.csv', index=False)\n",
    "# print(f\"Cleaned dataset: {len(df_clean)} samples (removed {len(problematic_indices)} files)\")\n",
    "# print(f\"Original: {len(df)} â†’ Cleaned: {len(df_clean)}\")\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# RANDOM_SEED = 42\n",
    "\n",
    "# train_val_df, test_df = train_test_split(\n",
    "#     df_clean, \n",
    "#     test_size=0.15, \n",
    "#     random_state=RANDOM_SEED,\n",
    "#     stratify=df_clean['label'] \n",
    "# )\n",
    "\n",
    "# train_df, val_df = train_test_split(\n",
    "#     train_val_df,\n",
    "#     test_size=15/85,  \n",
    "#     random_state=RANDOM_SEED,\n",
    "#     stratify=train_val_df['label']  \n",
    "# )\n",
    "\n",
    "\n",
    "# print(f\"Train set: {len(train_df)} samples ({len(train_df)/len(df_clean)*100:.1f}%)\")\n",
    "# print(f\"Validation set: {len(val_df)} samples ({len(val_df)/len(df_clean)*100:.1f}%)\")\n",
    "# print(f\"Test set: {len(test_df)} samples ({len(test_df)/len(df_clean)*100:.1f}%)\")\n",
    "# print(f\"\\nTrain label distribution:\\n{train_df['label'].value_counts().sort_index()}\")\n",
    "# print(f\"\\nVal label distribution:\\n{val_df['label'].value_counts().sort_index()}\")\n",
    "# print(f\"\\nTest label distribution:\\n{test_df['label'].value_counts().sort_index()}\")\n",
    "\n",
    "\n",
    "# # Save cleaned splits\n",
    "# train_df.to_csv('toy_data/split/train_df.csv', index=False)\n",
    "# val_df.to_csv('toy_data/split/val_df.csv', index=False)\n",
    "# test_df.to_csv('toy_data/split/test_df.csv', index=False)\n",
    "\n",
    "# # Save the problematic files list for reference\n",
    "# if problematic_indices:\n",
    "#     problematic_df = df.iloc[problematic_indices]\n",
    "#     problematic_df.to_csv('toy_data/split/problematic_files.csv', index=False)\n",
    "#     print(f\"\\nðŸ’¾ Problematic files saved to 'toy_data/split/problematic_files.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e2f57b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned splits\n",
    "train_df.to_csv('data_split/train_df.csv', index=False)\n",
    "val_df.to_csv('data_split/val_df.csv', index=False)\n",
    "test_df.to_csv('data_split/test_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2171611",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv ('/mnt/storage1/shourovj/shourovj_works/Auburn/data_split/train_df.csv')\n",
    "val_df = pd.read_csv ('/mnt/storage1/shourovj/shourovj_works/Auburn/data_split/val_df.csv')\n",
    "test_df = pd.read_csv ('/mnt/storage1/shourovj/shourovj_works/Auburn/data_split/test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df7c882e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d4124f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "feature",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cluster",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "7b0c44d0-c21c-4786-b06e-094e28a729a4",
       "rows": [
        [
         "0",
         "s_119_feature.mat",
         "s_119_cluster_index.mat",
         "1"
        ],
        [
         "1",
         "s_437_feature.mat",
         "s_437_cluster_index.mat",
         "2"
        ],
        [
         "2",
         "s_441_feature.mat",
         "s_441_cluster_index.mat",
         "2"
        ],
        [
         "3",
         "s_416_feature.mat",
         "s_416_cluster_index.mat",
         "2"
        ],
        [
         "4",
         "s_315_feature.mat",
         "s_315_cluster_index.mat",
         "2"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>cluster</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s_119_feature.mat</td>\n",
       "      <td>s_119_cluster_index.mat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s_437_feature.mat</td>\n",
       "      <td>s_437_cluster_index.mat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s_441_feature.mat</td>\n",
       "      <td>s_441_cluster_index.mat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s_416_feature.mat</td>\n",
       "      <td>s_416_cluster_index.mat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s_315_feature.mat</td>\n",
       "      <td>s_315_cluster_index.mat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature                  cluster  label\n",
       "0  s_119_feature.mat  s_119_cluster_index.mat      1\n",
       "1  s_437_feature.mat  s_437_cluster_index.mat      2\n",
       "2  s_441_feature.mat  s_441_cluster_index.mat      2\n",
       "3  s_416_feature.mat  s_416_cluster_index.mat      2\n",
       "4  s_315_feature.mat  s_315_cluster_index.mat      2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96e817b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature file path: s_119_feature.mat\n",
      "(400, 1632)\n",
      "cluster file path: s_119_cluster_index.mat\n",
      "(45, 54, 45)\n",
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "# sample_feature_file = train_df.iloc[0]['feature']\n",
    "# print(f\"Feature file path: {sample_feature_file}\")\n",
    "# sample_feature_data = sio.loadmat(data_dir + sample_feature_file)\n",
    "# # print(f\"Keys in feature file: {sample_feature_data.keys()}\")\n",
    "# print(sample_feature_data['feature_mat'].shape)\n",
    "\n",
    "\n",
    "# sample_cluster_file = train_df.iloc[0]['cluster']\n",
    "# print(f\"cluster file path: {sample_cluster_file}\")\n",
    "# sample_cluster_data = sio.loadmat(data_dir + sample_cluster_file)\n",
    "# # print(f\"Keys in feature file: {sample_cluster_data.keys()}\")\n",
    "# print(sample_cluster_data['cluster_index_mat'].shape)\n",
    "\n",
    "# sample_label = train_df.iloc[0]['label']\n",
    "# print(f\"Label: {sample_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fbf816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "\n",
    "data_dir = \"toy_data/\"\n",
    "class MRIDataset(data.Dataset):\n",
    "    def __init__(self, data_dir, df):\n",
    "        self.df = df\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        feature_file = row['feature']\n",
    "        cluster_file = row['cluster']\n",
    "        label = row['label']\n",
    "\n",
    "        # Load .mat files\n",
    "        f_data = sio.loadmat(self.data_dir + feature_file)\n",
    "        f_mat = f_data['feature_mat']  # Shape: (400, 1632) - ROI features\n",
    "        c_data = sio.loadmat(self.data_dir + cluster_file)\n",
    "        c_mat = c_data['cluster_index_mat']  # Shape: (45, 54, 45) - Cluster indices\n",
    "\n",
    "        # Convert to tensors\n",
    "        f_mat = torch.FloatTensor(f_mat)  # Feature matrix\n",
    "        c_mat = torch.LongTensor(c_mat)  # Cluster indices (integers)\n",
    "        label = torch.LongTensor([label - 1])  # Convert to 0-indexed (1,2 -> 0,1)\n",
    "\n",
    "        return f_mat, c_mat, label\n",
    "\n",
    "\n",
    "train_dataset = MRIDataset(data_dir, train_df)\n",
    "val_dataset = MRIDataset(data_dir, val_df)\n",
    "test_dataset = MRIDataset(data_dir, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3132472e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "173b64b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "ex = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7844f8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 400, 1632])\n",
      "torch.Size([16, 45, 54, 45])\n",
      "torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "feature = ex[0]\n",
    "cluster = ex[1]\n",
    "label = ex[2]\n",
    "\n",
    "print(feature.shape)\n",
    "print(cluster.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441f98ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d4b0e66",
   "metadata": {},
   "source": [
    "Without positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "03ba24ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import einops\n",
    "\n",
    "# class ModelConfig:\n",
    "#     \"\"\"Configuration for Atlas-free Brain Network Transformer\"\"\"\n",
    "#     feature_dim = 1632  # ROI feature dimension\n",
    "#     num_rois = 400  # Number of ROIs\n",
    "#     cluster_shape = (45, 54, 45)  # 3D cluster index shape\n",
    "#     hidden_dim = 16  # Latent dimension V (projection dimension)\n",
    "#     num_heads = 4  # Number of attention heads\n",
    "#     num_layers = 1  # Number of transformer layers\n",
    "#     intermediate_dim = 32*4  # Feed-forward network dimension\n",
    "#     dropout = 0.4\n",
    "#     block_size = 9  # Spatial block size (K x K x K)\n",
    "#     block_stride = 5  # Stride for block pooling\n",
    "#     output_dim = 2  # Binary classification\n",
    "\n",
    "\n",
    "\n",
    "# class MultiHeadAttention(nn.Module):\n",
    "#     \"\"\"Standard Multi-Head Self-Attention\"\"\"\n",
    "#     def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "#         super().__init__()\n",
    "#         assert d_model % num_heads == 0\n",
    "        \n",
    "#         self.d_model = d_model\n",
    "#         self.num_heads = num_heads\n",
    "#         self.head_dim = d_model // num_heads\n",
    "        \n",
    "#         self.w_q = nn.Linear(d_model, d_model)\n",
    "#         self.w_k = nn.Linear(d_model, d_model)\n",
    "#         self.w_v = nn.Linear(d_model, d_model)\n",
    "#         self.w_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.scale = self.head_dim ** -0.5\n",
    "        \n",
    "#     def forward(self, x, mask=None):\n",
    "#         batch_size, seq_len, d_model = x.size()\n",
    "        \n",
    "#         # Linear projections\n",
    "#         Q = self.w_q(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "#         K = self.w_k(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "#         V = self.w_v(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "#         # Scaled dot-product attention\n",
    "#         scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale\n",
    "        \n",
    "#         if mask is not None:\n",
    "#             scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "#         attn_weights = F.softmax(scores, dim=-1)\n",
    "#         attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "#         # Apply attention to values\n",
    "#         attn_output = torch.matmul(attn_weights, V)\n",
    "        \n",
    "#         # Concatenate heads\n",
    "#         attn_output = attn_output.transpose(1, 2).contiguous().view(\n",
    "#             batch_size, seq_len, d_model\n",
    "#         )\n",
    "        \n",
    "#         # Final linear projection\n",
    "#         output = self.w_o(attn_output)\n",
    "#         return output\n",
    "\n",
    "\n",
    "# class TransformerBlock(nn.Module):\n",
    "#     \"\"\"Standard Transformer Encoder Block\"\"\"\n",
    "#     def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.norm1 = nn.LayerNorm(d_model)\n",
    "#         self.attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "\n",
    "#         self.norm2 = nn.LayerNorm(d_model)\n",
    "#         self.ffn = nn.Sequential(\n",
    "#             nn.Linear(d_model, d_ff),\n",
    "#             nn.GELU(),\n",
    "#             nn.Dropout(dropout),\n",
    "#             nn.Linear(d_ff, d_model),\n",
    "#             nn.Dropout(dropout)\n",
    "#         )\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "#     def forward(self, x, mask=None):\n",
    "#         # Self-attention with residual connection\n",
    "#         x = x + self.dropout(self.attn(self.norm1(x), mask))\n",
    "#         # Feed-forward with residual connection\n",
    "#         x = x + self.ffn(self.norm2(x))\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class BrainNet(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Atlas-free Brain Network Transformer\n",
    "    \n",
    "#     Architecture:\n",
    "#     1. ROI Connectivity Projection (g â†’ q): Linear projection from feature_dim to hidden_dim\n",
    "#     2. 3D Multi-channel Brain Map Construction (Q): Map ROI features to voxel space using cluster indices\n",
    "#     3. Spatial Block Tokenization: Divide 3D volume into blocks and pool\n",
    "#     4. Transformer Encoder: Process spatial tokens\n",
    "#     5. Global Readout & Classification: Mean pool and classify\n",
    "#     \"\"\"\n",
    "#     def __init__(self, config):\n",
    "#         super().__init__()\n",
    "#         self.config = config\n",
    "        \n",
    "\n",
    "#         # Step 1: ROI Connectivity Projection (g â†’ q)\n",
    "#         # Simple linear projection as per paper (can be extended to MLP if needed)\n",
    "#         self.roi_projection = nn.Linear(config.feature_dim, config.hidden_dim)\n",
    "#         # self.roi_projection = nn.Sequential(\n",
    "#         #     nn.Linear(1632, 16), \n",
    "#         #     # nn.BatchNorm1d(400), # Standardize across ROIs\n",
    "#         #     nn.GELU(),\n",
    "#         #     nn.Dropout(0.5),     # Force the model to not rely on specific input features\n",
    "#         #     nn.Linear(16, 32)    \n",
    "#         # )\n",
    "        \n",
    "#         # Step 2-3: Spatial Block Tokenization will be done in forward pass\n",
    "#         # We'll use adaptive pooling to handle variable spatial dimensions\n",
    "        \n",
    "#         # Step 4: Transformer Encoder\n",
    "#         self.transformer_blocks = nn.ModuleList([\n",
    "#             TransformerBlock(\n",
    "#                 config.hidden_dim,\n",
    "#                 config.num_heads,\n",
    "#                 config.intermediate_dim,\n",
    "#                 config.dropout\n",
    "#             )\n",
    "#             for _ in range(config.num_layers)\n",
    "#         ])\n",
    "        \n",
    "#         # Step 5: Global Readout & Classification\n",
    "#         self.global_pool = nn.AdaptiveAvgPool1d(1)  # Global average pooling\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.LayerNorm(config.hidden_dim),\n",
    "#             nn.Dropout(config.dropout),\n",
    "#             nn.Linear(config.hidden_dim, config.output_dim)\n",
    "#         )\n",
    "    \n",
    "#     def _construct_3d_brain_map(self, q, c_mat):\n",
    "#         \"\"\"\n",
    "#         Construct 3D Multi-channel Brain Map (Q) from ROI features and cluster indices.\n",
    "        \n",
    "#         The cluster index matrix C contains:\n",
    "#         - 0: background (should remain zero in output)\n",
    "#         - 1-400: ROI indices (i-th ROI corresponds to (i-1)-th row of feature matrix F)\n",
    "        \n",
    "#         The feature matrix F has shape [400, feature_dim], where:\n",
    "#         - Row 0 corresponds to ROI 1\n",
    "#         - Row 1 corresponds to ROI 2\n",
    "#         - ...\n",
    "#         - Row 399 corresponds to ROI 400\n",
    "        \n",
    "#         Args:\n",
    "#             q: Projected ROI features [batch_size, num_rois, hidden_dim]\n",
    "#                q[b, i] is the projected feature for ROI (i+1) (i-th row of F)\n",
    "#             c_mat: Cluster index matrix [batch_size, D, H, W]\n",
    "#                    Contains ROI indices: 0 (background), 1-400 (ROI indices)\n",
    "        \n",
    "#         Returns:\n",
    "#             Q: 3D brain map [batch_size, hidden_dim, D, H, W]\n",
    "#                Background voxels (c_mat == 0) remain zero in Q\n",
    "#         \"\"\"\n",
    "#         batch_size, num_rois, hidden_dim = q.shape\n",
    "#         D, H, W = c_mat.shape[1], c_mat.shape[2], c_mat.shape[3]\n",
    "        \n",
    "#         # Initialize output tensor (background will remain zero)\n",
    "#         Q = torch.zeros(batch_size, hidden_dim, D, H, W, \n",
    "#                         device=q.device, dtype=q.dtype)\n",
    "        \n",
    "#         # Process each sample in the batch\n",
    "#         for b in range(batch_size):\n",
    "#             # Get cluster indices for this batch [D, H, W]\n",
    "#             cluster_indices = c_mat[b]  # Contains: 0 (background), 1-400 (ROI indices)\n",
    "            \n",
    "#             # Get projected features for this batch [num_rois, hidden_dim]\n",
    "#             # q[b, i] corresponds to ROI (i+1), so q[b, 0] = ROI 1, q[b, 399] = ROI 400\n",
    "#             roi_features = q[b]\n",
    "            \n",
    "#             # Flatten spatial dimensions to get all voxel positions\n",
    "#             cluster_indices_flat = cluster_indices.flatten()  # [D*H*W]\n",
    "            \n",
    "#             # Create mask for non-background voxels (ROI indices 1-400)\n",
    "#             non_bg_mask = (cluster_indices_flat > 0) & (cluster_indices_flat <= num_rois)\n",
    "            \n",
    "#             # Convert ROI indices from 1-based (1-400) to 0-based (0-399) for indexing into q\n",
    "#             # ROI 1 -> index 0, ROI 2 -> index 1, ..., ROI 400 -> index 399\n",
    "#             roi_indices = (cluster_indices_flat[non_bg_mask] - 1).long()\n",
    "            \n",
    "#             # Map non-background voxels to their corresponding ROI feature vectors\n",
    "#             # Background voxels (value 0) remain zero in Q\n",
    "#             voxel_features = torch.zeros(D * H * W, hidden_dim, \n",
    "#                                         device=q.device, dtype=q.dtype)\n",
    "#             voxel_features[non_bg_mask] = roi_features[roi_indices]  # [num_non_bg, hidden_dim]\n",
    "            \n",
    "#             # Reshape back to 3D spatial structure\n",
    "#             # Transpose to get [hidden_dim, D, H, W] format\n",
    "#             Q[b] = voxel_features.view(D, H, W, hidden_dim).permute(3, 0, 1, 2)\n",
    "        \n",
    "#         return Q\n",
    "        \n",
    "#     def forward(self, f_mat, c_mat):\n",
    "#         \"\"\"\n",
    "#         Forward pass\n",
    "        \n",
    "#         Args:\n",
    "#             f_mat: Feature matrix [batch_size, num_rois, feature_dim] - ROI features\n",
    "#             c_mat: Cluster index matrix [batch_size, D, H, W] - 3D cluster indices\n",
    "        \n",
    "#         Returns:\n",
    "#             logits: [batch_size, output_dim]\n",
    "#         \"\"\"\n",
    "#         batch_size = f_mat.size(0)\n",
    "        \n",
    "#         # Step 1: ROI Connectivity Projection (g â†’ q)\n",
    "#         # f_mat: [B, num_rois, feature_dim] â†’ [B, num_rois, hidden_dim]\n",
    "#         q = self.roi_projection(f_mat)  # [B, num_rois, hidden_dim]\n",
    "        \n",
    "#         # Step 2: 3D Multi-channel Brain Map Construction (Q)\n",
    "#         # Map ROI features back to voxel space using cluster indices\n",
    "#         # Each voxel position in c_mat contains an ROI index (1-400)\n",
    "#         # This function maps the corresponding ROI feature vector to each voxel position\n",
    "#         Q = self._construct_3d_brain_map(q, c_mat)  # [B, hidden_dim, D, H, W]\n",
    "        \n",
    "#         D, H, W = Q.shape[2], Q.shape[3], Q.shape[4]\n",
    "        \n",
    "#         # Step 3: Spatial Block Tokenization\n",
    "#         # ====================================\n",
    "#         # This step divides the 3D brain volume into smaller blocks and creates \"tokens\" \n",
    "#         # (like words in a sentence) for the Transformer to process.\n",
    "#         #\n",
    "#         # INPUT: Q [B, hidden_dim, D=45, H=54, W=45] - 3D brain map with features at each voxel\n",
    "#         #\n",
    "#         # PROCESS:\n",
    "#         # 1. Divide volume into overlapping blocks of size block_sizeÃ—block_sizeÃ—block_size (e.g., 9Ã—9Ã—9)\n",
    "#         # 2. For each block, sum all the feature values within that block\n",
    "#         # 3. This creates one \"token\" per block\n",
    "#         #\n",
    "#         # EXAMPLE (simplified 2D):\n",
    "#         #   Original: [45Ã—54] voxels\n",
    "#         #   Blocks: 9Ã—9 blocks with stride 5\n",
    "#         #   Output: ~8Ã—10 blocks = 80 tokens\n",
    "#         #\n",
    "#         # WHY SUM-POOLING?\n",
    "#         # The paper uses sum-pooling (not average) because:\n",
    "#         # - It preserves the total \"activation\" in each spatial region\n",
    "#         # - More sensitive to the amount of information in each block\n",
    "#         # - Better for capturing spatial patterns\n",
    "        \n",
    "#         # Use 3D average pooling with kernel=block_size and stride=block_stride\n",
    "#         # PyTorch doesn't have direct sum-pooling, so we:\n",
    "#         # 1. Use avg_pool3d to get average values in each block\n",
    "#         # 2. Multiply by block_size^3 to convert to sum\n",
    "#         #    (sum = average Ã— number_of_elements_in_block)\n",
    "#         #    For 9Ã—9Ã—9 block: sum = avg Ã— 729\n",
    "#         Q_pooled = F.avg_pool3d(\n",
    "#             Q,\n",
    "#             kernel_size=self.config.block_size,  # e.g., 9 (creates 9Ã—9Ã—9 blocks)\n",
    "#             stride=self.config.block_stride,     # e.g., 5 (blocks overlap)\n",
    "#             padding=0  # No padding - only process valid blocks\n",
    "#         ) * (self.config.block_size ** 3)  # Convert avg â†’ sum: multiply by voxels per block\n",
    "        \n",
    "#         # Get output dimensions after pooling\n",
    "#         # For D=45, H=54, W=45 with block_size=9, stride=5:\n",
    "#         #   D_out = (45 - 9) // 5 + 1 = 8\n",
    "#         #   H_out = (54 - 9) // 5 + 1 = 10  \n",
    "#         #   W_out = (45 - 9) // 5 + 1 = 8\n",
    "#         #   Total tokens = 8 Ã— 10 Ã— 8 = 640 tokens\n",
    "#         D_out, H_out, W_out = Q_pooled.shape[2], Q_pooled.shape[3], Q_pooled.shape[4]\n",
    "        \n",
    "#         # Flatten spatial dimensions to create sequence of tokens for Transformer\n",
    "#         # Q_pooled: [B, hidden_dim, D_out, H_out, W_out]\n",
    "#         # tokens: [B, num_tokens, hidden_dim] - each token is a spatial block\n",
    "#         num_tokens = D_out * H_out * W_out\n",
    "#         tokens = Q_pooled.view(batch_size, self.config.hidden_dim, num_tokens)\n",
    "#         tokens = tokens.transpose(1, 2)  # [B, num_tokens, hidden_dim]\n",
    "        \n",
    "#         # Now we have a sequence of tokens where each token represents a spatial block\n",
    "#         # The Transformer will process these tokens to learn relationships between\n",
    "#         # different brain regions (spatial blocks)\n",
    "        \n",
    "#         # Step 4: Transformer Encoder\n",
    "#         # Process the sequence of spatial tokens through transformer blocks\n",
    "#         # Each token can now \"attend\" to all other tokens to learn relationships\n",
    "#         x = tokens  # [B, num_tokens, hidden_dim]\n",
    "#         for transformer_block in self.transformer_blocks:\n",
    "#             x = transformer_block(x)  # Still [B, num_tokens, hidden_dim]\n",
    "        \n",
    "#         # Step 5: Global Readout & Classification\n",
    "#         # ======================================\n",
    "#         # GOAL: Convert sequence of tokens â†’ single feature vector per sample\n",
    "#         #\n",
    "#         # After transformer: x = [B, num_tokens=640, hidden_dim=64]\n",
    "#         # We have 640 tokens, each with 64 features\n",
    "#         # We want: [B, hidden_dim=64] - one vector representing the entire brain\n",
    "#         #\n",
    "#         # WHY TRANSPOSE?\n",
    "#         # - AdaptiveAvgPool1d pools over the LAST dimension\n",
    "#         # - We want to pool over tokens (dimension 1), not features (dimension 2)\n",
    "#         # - So we transpose: [B, num_tokens, hidden_dim] â†’ [B, hidden_dim, num_tokens]\n",
    "#         # - Now tokens are the last dimension, so pooling works correctly\n",
    "#         #\n",
    "#         # WHAT DOES GLOBAL POOLING DO?\n",
    "#         # - Takes average of all 640 tokens\n",
    "#         # - Result: One feature vector per sample representing the whole brain\n",
    "#         # - This is the \"readout\" operation - aggregating all spatial information\n",
    "#         x = x.transpose(1, 2)  # [B, hidden_dim, num_tokens] - swap dims for pooling\n",
    "#         x = self.global_pool(x).squeeze(-1)  # [B, hidden_dim, 1] â†’ [B, hidden_dim]\n",
    "        \n",
    "#         # Classification\n",
    "#         # Now we have one feature vector per brain, ready for classification\n",
    "#         logits = self.classifier(x)  # [B, hidden_dim] â†’ [B, output_dim=2]\n",
    "        \n",
    "#         return logits\n",
    "\n",
    "\n",
    "# # Create model instance\n",
    "# config = ModelConfig()\n",
    "# model = BrainNet(config)\n",
    "\n",
    "# # Print model summary\n",
    "# print(f\"Model created with {sum(p.numel() for p in model.parameters())/10e6} parameters\")\n",
    "# print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)/10e6}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d228670d",
   "metadata": {},
   "source": [
    "With positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11f0c0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FIXED MODEL CREATED!\n",
      "   Parameters: 0.119M\n",
      "   hidden_dim: 16\n",
      "   num_layers: 1\n",
      "\n",
      "\n",
      "BrainNet(\n",
      "  (roi_projection): Sequential(\n",
      "    (0): Linear(in_features=1632, out_features=64, bias=True)\n",
      "    (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): GELU(approximate='none')\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=64, out_features=16, bias=True)\n",
      "  )\n",
      "  (transformer_blocks): ModuleList(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): MultiHeadAttention(\n",
      "        (w_q): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (w_k): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (w_v): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (w_o): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "        (3): Linear(in_features=64, out_features=16, bias=True)\n",
      "        (4): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (global_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "    (2): Linear(in_features=16, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ModelConfig:\n",
    "    \"\"\"Configuration for Atlas-free Brain Network Transformer (FIXED)\"\"\"\n",
    "    feature_dim = 1632  # ROI feature dimension\n",
    "    num_rois = 400  # Number of ROIs\n",
    "    cluster_shape = (45, 54, 45)  # 3D cluster index shape\n",
    "    hidden_dim = 16  # Balanced size (was 16 - too small, 64 - might overfit)\n",
    "    num_heads = 4  # Number of attention heads\n",
    "    num_layers = 1  # Balanced (was 1 - too small, 3 - might overfit)\n",
    "    intermediate_dim = hidden_dim * 4\n",
    "    dropout = 0.5\n",
    "    block_size = 9  # Spatial block size (K x K x K)\n",
    "    block_stride = 5  # Stride for block pooling\n",
    "    output_dim = 2  # Binary classification\n",
    "    \n",
    "    def __init__(self):\n",
    "        if self.intermediate_dim is None:\n",
    "            self.intermediate_dim = self.hidden_dim * 4  # FIX: Consistent with hidden_dim\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Standard Multi-Head Self-Attention\"\"\"\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        \n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, seq_len, d_model = x.size()\n",
    "        \n",
    "        # Linear projections\n",
    "        Q = self.w_q(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = self.w_k(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = self.w_v(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        attn_output = torch.matmul(attn_weights, V)\n",
    "        \n",
    "        # Concatenate heads\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(\n",
    "            batch_size, seq_len, d_model\n",
    "        )\n",
    "        \n",
    "        # Final linear projection\n",
    "        output = self.w_o(attn_output)\n",
    "        return output\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"Standard Transformer Encoder Block\"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        # Self-attention with residual connection\n",
    "        x = x + self.dropout(self.attn(self.norm1(x), mask))\n",
    "        # Feed-forward with residual connection\n",
    "        x = x + self.ffn(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class BrainNet(nn.Module):\n",
    "    \"\"\"Atlas-free Brain Network Transformer (FIXED VERSION)\"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # Step 1: ROI Connectivity Projection (FIXED: BatchNorm1d â†’ LayerNorm)\n",
    "        self.roi_projection = nn.Sequential(\n",
    "            nn.Linear(config.feature_dim, 64),  # Intermediate dimension\n",
    "            nn.LayerNorm(64),  # FIX: LayerNorm works on last dimension [B, num_rois, 64]\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, config.hidden_dim)\n",
    "        )\n",
    "\n",
    "        # # Step 1: ROI Connectivity Projection (FIXED: BatchNorm1d â†’ LayerNorm)\n",
    "        # self.roi_projection = nn.Sequential(\n",
    "        #     nn.Linear(config.feature_dim, config.hidden_dim),  # Intermediate dimension\n",
    "        #     nn.LayerNorm(64),  # FIX: LayerNorm works on last dimension [B, num_rois, 64]\n",
    "        #     nn.GELU(),\n",
    "        #     nn.Dropout(0.5),\n",
    "        # )\n",
    "        \n",
    "        # 2. DYNAMIC CALCULATION of Token Count\n",
    "        # Extract dimensions from config\n",
    "        D_in, H_in, W_in = config.cluster_shape\n",
    "        K = config.block_size\n",
    "        S = config.block_stride\n",
    "        \n",
    "        # Calculate the number of nodes after 3D pooling and sum-pooling\n",
    "        self.D_out = (D_in - K) // S + 1\n",
    "        self.H_out = (H_in - K) // S + 1\n",
    "        self.W_out = (W_in - K) // S + 1\n",
    "        \n",
    "        self.num_tokens = self.D_out * self.H_out * self.W_out\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, self.num_tokens, config.hidden_dim))\n",
    "        \n",
    "        # Step 4: Transformer Encoder\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(\n",
    "                config.hidden_dim,\n",
    "                config.num_heads,\n",
    "                config.intermediate_dim,\n",
    "                config.dropout\n",
    "            )\n",
    "            for _ in range(config.num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Step 5: Global Readout & Classification\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(config.hidden_dim),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.hidden_dim, config.output_dim)\n",
    "        )\n",
    "    \n",
    "    def _construct_3d_brain_map(self, q, c_mat):\n",
    "\n",
    "        batch_size, num_rois, hidden_dim = q.shape\n",
    "        D, H, W = c_mat.shape[1], c_mat.shape[2], c_mat.shape[3]\n",
    "        \n",
    "        # Initialize output tensor (background will remain zero)\n",
    "        Q = torch.zeros(batch_size, hidden_dim, D, H, W, \n",
    "                        device=q.device, dtype=q.dtype)\n",
    "        \n",
    "        # Process each sample in the batch\n",
    "        for b in range(batch_size):\n",
    "            # Get cluster indices for this batch [D, H, W]\n",
    "            cluster_indices = c_mat[b]  # Contains: 0 (background), 1-400 (ROI indices)\n",
    "            \n",
    "            # Get projected features for this batch [num_rois, hidden_dim]\n",
    "            # q[b, i] corresponds to ROI (i+1), so q[b, 0] = ROI 1, q[b, 399] = ROI 400\n",
    "            roi_features = q[b]\n",
    "            \n",
    "            # Flatten spatial dimensions to get all voxel positions\n",
    "            cluster_indices_flat = cluster_indices.flatten()  # [D*H*W]\n",
    "            \n",
    "            # Create mask for non-background voxels (ROI indices 1-400)\n",
    "            non_bg_mask = (cluster_indices_flat > 0) & (cluster_indices_flat <= num_rois)\n",
    "            \n",
    "            # Convert ROI indices from 1-based (1-400) to 0-based (0-399) for indexing into q\n",
    "            # ROI 1 -> index 0, ROI 2 -> index 1, ..., ROI 400 -> index 399\n",
    "            roi_indices = (cluster_indices_flat[non_bg_mask] - 1).long()\n",
    "            \n",
    "            # Map non-background voxels to their corresponding ROI feature vectors\n",
    "            # Background voxels (value 0) remain zero in Q\n",
    "            voxel_features = torch.zeros(D * H * W, hidden_dim, \n",
    "                                        device=q.device, dtype=q.dtype)\n",
    "            voxel_features[non_bg_mask] = roi_features[roi_indices]  # [num_non_bg, hidden_dim]\n",
    "            \n",
    "            # Reshape back to 3D spatial structure\n",
    "            # Transpose to get [hidden_dim, D, H, W] format\n",
    "            Q[b] = voxel_features.view(D, H, W, hidden_dim).permute(3, 0, 1, 2)\n",
    "        \n",
    "        return Q\n",
    "\n",
    "    \n",
    "    def forward(self, f_mat, c_mat):\n",
    "        batch_size = f_mat.size(0)\n",
    "        \n",
    "        q = self.roi_projection(f_mat)  # [B, num_rois, hidden_dim]\n",
    "        \n",
    "        Q = self._construct_3d_brain_map(q, c_mat)  # [B, hidden_dim, D, H, W]\n",
    "        \n",
    "        Q_pooled = F.avg_pool3d(\n",
    "            Q,\n",
    "            kernel_size=self.config.block_size,\n",
    "            stride=self.config.block_stride,\n",
    "            padding=0\n",
    "        ) * (self.config.block_size ** 3)  \n",
    "\n",
    "        D_out, H_out, W_out = Q_pooled.shape[2], Q_pooled.shape[3], Q_pooled.shape[4]\n",
    "        num_tokens = D_out * H_out * W_out\n",
    "        \n",
    "        if num_tokens != self.num_tokens:\n",
    "            self.pos_embedding = nn.Parameter(\n",
    "                torch.randn(1, num_tokens, self.config.hidden_dim, device=Q_pooled.device)\n",
    "            ).to(Q_pooled.device)\n",
    "            self.num_tokens = num_tokens\n",
    "        \n",
    "        tokens = Q_pooled.view(batch_size, self.config.hidden_dim, num_tokens)\n",
    "        tokens = tokens.transpose(1, 2)  # [B, num_tokens, hidden_dim]\n",
    "        \n",
    "        x = tokens + self.pos_embedding\n",
    "        for transformer_block in self.transformer_blocks:\n",
    "            x = transformer_block(x)\n",
    "        \n",
    "        x = x.transpose(1, 2)  # [B, hidden_dim, num_tokens]\n",
    "        x = self.global_pool(x).squeeze(-1)  # [B, hidden_dim]\n",
    "        logits = self.classifier(x)  # [B, output_dim]\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# Create fixed model\n",
    "config = ModelConfig()\n",
    "model = BrainNet(config)\n",
    "\n",
    "print(\"âœ… FIXED MODEL CREATED!\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in model_fixed.parameters())/1e6:.3f}M\")\n",
    "print(f\"   hidden_dim: {config.hidden_dim}\")\n",
    "print(f\"   num_layers: {config.num_layers}\\n\\n\")\n",
    "\n",
    "# print(f\"   intermediate_dim: {config.intermediate_dim} (fixed: hidden_dim * 4)\")\n",
    "# print(\"\\nâœ… All bugs fixed:\")\n",
    "# print(\"   1. BatchNorm1d â†’ LayerNorm\")\n",
    "# print(\"   2. intermediate_dim consistent\")\n",
    "# print(\"   3. _construct_3d_brain_map fixed\")\n",
    "# print(\"   4. Balanced model size\")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b4416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e98ffb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "======================================================================\n",
      "Starting Training\n",
      "======================================================================\n",
      "Model parameters: 0.12M\n",
      "Training samples: 340\n",
      "Validation samples: 73\n",
      "Number of epochs: 50\n",
      "Weight decay: 1e-3 (strong regularization)\n",
      "Early stopping patience: 10\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:11<00:00,  1.87it/s, loss=0.5804, acc=50.59%]\n",
      "Epoch 1/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.02it/s, loss=0.7099, acc=52.05%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50:\n",
      "  Train Loss: 0.7861 | Train Acc: 50.59%\n",
      "  Val Loss:   0.7012 | Val Acc:   52.05%\n",
      "  LR: 1.00e-04\n",
      "  âœ“ Saved best model (Val Acc: 52.05%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.18it/s, loss=0.6308, acc=52.94%]\n",
      "Epoch 2/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.57it/s, loss=0.7072, acc=54.79%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/50:\n",
      "  Train Loss: 0.7074 | Train Acc: 52.94%\n",
      "  Val Loss:   0.6956 | Val Acc:   54.79%\n",
      "  LR: 1.00e-04\n",
      "  âœ“ Saved best model (Val Acc: 54.79%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.22it/s, loss=0.7956, acc=57.06%]\n",
      "Epoch 3/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.45it/s, loss=0.7052, acc=52.05%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/50:\n",
      "  Train Loss: 0.6893 | Train Acc: 57.06%\n",
      "  Val Loss:   0.6918 | Val Acc:   52.05%\n",
      "  LR: 1.00e-04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.14it/s, loss=0.5420, acc=59.71%]\n",
      "Epoch 4/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.56it/s, loss=0.7054, acc=60.27%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/50:\n",
      "  Train Loss: 0.6525 | Train Acc: 59.71%\n",
      "  Val Loss:   0.6882 | Val Acc:   60.27%\n",
      "  LR: 1.00e-04\n",
      "  âœ“ Saved best model (Val Acc: 60.27%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.14it/s, loss=0.7166, acc=66.76%]\n",
      "Epoch 5/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.46it/s, loss=0.6918, acc=56.16%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/50:\n",
      "  Train Loss: 0.6339 | Train Acc: 66.76%\n",
      "  Val Loss:   0.6852 | Val Acc:   56.16%\n",
      "  LR: 1.00e-04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.18it/s, loss=0.5802, acc=68.82%]\n",
      "Epoch 6/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.56it/s, loss=0.6906, acc=60.27%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/50:\n",
      "  Train Loss: 0.5923 | Train Acc: 68.82%\n",
      "  Val Loss:   0.6760 | Val Acc:   60.27%\n",
      "  LR: 1.00e-04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.16it/s, loss=0.6897, acc=72.94%]\n",
      "Epoch 7/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.55it/s, loss=0.6958, acc=63.01%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/50:\n",
      "  Train Loss: 0.5562 | Train Acc: 72.94%\n",
      "  Val Loss:   0.6672 | Val Acc:   63.01%\n",
      "  LR: 1.00e-04\n",
      "  âœ“ Saved best model (Val Acc: 63.01%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:07<00:00,  3.06it/s, loss=0.2352, acc=84.12%]\n",
      "Epoch 8/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.54it/s, loss=0.6917, acc=65.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/50:\n",
      "  Train Loss: 0.4331 | Train Acc: 84.12%\n",
      "  Val Loss:   0.6602 | Val Acc:   65.75%\n",
      "  LR: 1.00e-04\n",
      "  âœ“ Saved best model (Val Acc: 65.75%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.19it/s, loss=0.2309, acc=87.35%]\n",
      "Epoch 9/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.39it/s, loss=0.8927, acc=56.16%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/50:\n",
      "  Train Loss: 0.3280 | Train Acc: 87.35%\n",
      "  Val Loss:   0.7378 | Val Acc:   56.16%\n",
      "  LR: 1.00e-04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.19it/s, loss=0.2395, acc=93.24%]\n",
      "Epoch 10/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.47it/s, loss=0.8067, acc=54.79%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/50:\n",
      "  Train Loss: 0.2611 | Train Acc: 93.24%\n",
      "  Val Loss:   0.7032 | Val Acc:   54.79%\n",
      "  LR: 1.00e-04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.14it/s, loss=0.1267, acc=95.29%]\n",
      "Epoch 11/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.52it/s, loss=0.6365, acc=67.12%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/50:\n",
      "  Train Loss: 0.2130 | Train Acc: 95.29%\n",
      "  Val Loss:   0.6229 | Val Acc:   67.12%\n",
      "  LR: 1.00e-04\n",
      "  âœ“ Saved best model (Val Acc: 67.12%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:07<00:00,  3.12it/s, loss=0.2957, acc=97.94%]\n",
      "Epoch 12/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.45it/s, loss=0.6004, acc=68.49%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/50:\n",
      "  Train Loss: 0.1772 | Train Acc: 97.94%\n",
      "  Val Loss:   0.6064 | Val Acc:   68.49%\n",
      "  LR: 1.00e-04\n",
      "  âœ“ Saved best model (Val Acc: 68.49%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.16it/s, loss=0.2371, acc=98.82%] \n",
      "Epoch 13/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.48it/s, loss=0.5597, acc=72.60%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/50:\n",
      "  Train Loss: 0.1592 | Train Acc: 98.82%\n",
      "  Val Loss:   0.6095 | Val Acc:   72.60%\n",
      "  LR: 1.00e-04\n",
      "  âœ“ Saved best model (Val Acc: 72.60%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.20it/s, loss=0.1098, acc=97.65%]\n",
      "Epoch 14/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.45it/s, loss=0.7120, acc=64.38%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/50:\n",
      "  Train Loss: 0.1516 | Train Acc: 97.65%\n",
      "  Val Loss:   0.6612 | Val Acc:   64.38%\n",
      "  LR: 1.00e-04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.21it/s, loss=0.0603, acc=98.53%]\n",
      "Epoch 15/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.50it/s, loss=0.6381, acc=67.12%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/50:\n",
      "  Train Loss: 0.1401 | Train Acc: 98.53%\n",
      "  Val Loss:   0.6247 | Val Acc:   67.12%\n",
      "  LR: 1.00e-04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:07<00:00,  3.11it/s, loss=0.1712, acc=99.41%]\n",
      "Epoch 16/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.46it/s, loss=0.5986, acc=67.12%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/50:\n",
      "  Train Loss: 0.1193 | Train Acc: 99.41%\n",
      "  Val Loss:   0.6242 | Val Acc:   67.12%\n",
      "  LR: 1.00e-04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.19it/s, loss=0.0623, acc=99.41%]\n",
      "Epoch 17/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.53it/s, loss=0.5489, acc=69.86%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/50:\n",
      "  Train Loss: 0.1128 | Train Acc: 99.41%\n",
      "  Val Loss:   0.6039 | Val Acc:   69.86%\n",
      "  LR: 1.00e-04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:07<00:00,  3.12it/s, loss=0.2947, acc=98.53%] \n",
      "Epoch 18/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.49it/s, loss=0.6036, acc=68.49%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/50:\n",
      "  Train Loss: 0.1278 | Train Acc: 98.53%\n",
      "  Val Loss:   0.6334 | Val Acc:   68.49%\n",
      "  LR: 1.00e-04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.20it/s, loss=0.1708, acc=99.12%] \n",
      "Epoch 19/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.34it/s, loss=0.6317, acc=68.49%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/50:\n",
      "  Train Loss: 0.1099 | Train Acc: 99.12%\n",
      "  Val Loss:   0.6513 | Val Acc:   68.49%\n",
      "  LR: 1.00e-04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:07<00:00,  3.07it/s, loss=0.1266, acc=100.00%]\n",
      "Epoch 20/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.12it/s, loss=0.5410, acc=72.60%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/50:\n",
      "  Train Loss: 0.1025 | Train Acc: 100.00%\n",
      "  Val Loss:   0.6181 | Val Acc:   72.60%\n",
      "  LR: 1.00e-04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.19it/s, loss=0.0550, acc=99.41%] \n",
      "Epoch 21/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.58it/s, loss=0.6033, acc=68.49%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21/50:\n",
      "  Train Loss: 0.0903 | Train Acc: 99.41%\n",
      "  Val Loss:   0.6364 | Val Acc:   68.49%\n",
      "  LR: 1.00e-04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.17it/s, loss=0.0895, acc=100.00%]\n",
      "Epoch 22/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.54it/s, loss=0.6097, acc=68.49%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22/50:\n",
      "  Train Loss: 0.0948 | Train Acc: 100.00%\n",
      "  Val Loss:   0.6422 | Val Acc:   68.49%\n",
      "  LR: 1.00e-04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.18it/s, loss=0.0741, acc=100.00%]\n",
      "Epoch 23/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.53it/s, loss=0.5388, acc=69.86%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23/50:\n",
      "  Train Loss: 0.0852 | Train Acc: 100.00%\n",
      "  Val Loss:   0.6217 | Val Acc:   69.86%\n",
      "  LR: 5.00e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.16it/s, loss=0.0452, acc=100.00%]\n",
      "Epoch 24/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.41it/s, loss=0.5723, acc=71.23%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24/50:\n",
      "  Train Loss: 0.0799 | Train Acc: 100.00%\n",
      "  Val Loss:   0.6378 | Val Acc:   71.23%\n",
      "  LR: 5.00e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:07<00:00,  3.10it/s, loss=0.1368, acc=100.00%]\n",
      "Epoch 25/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.99it/s, loss=0.5653, acc=69.86%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25/50:\n",
      "  Train Loss: 0.0742 | Train Acc: 100.00%\n",
      "  Val Loss:   0.6369 | Val Acc:   69.86%\n",
      "  LR: 5.00e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:07<00:00,  3.09it/s, loss=0.0537, acc=100.00%]\n",
      "Epoch 26/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.39it/s, loss=0.5719, acc=69.86%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26/50:\n",
      "  Train Loss: 0.0752 | Train Acc: 100.00%\n",
      "  Val Loss:   0.6407 | Val Acc:   69.86%\n",
      "  LR: 5.00e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:07<00:00,  3.12it/s, loss=0.0713, acc=100.00%]\n",
      "Epoch 27/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.55it/s, loss=0.5569, acc=73.97%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27/50:\n",
      "  Train Loss: 0.0726 | Train Acc: 100.00%\n",
      "  Val Loss:   0.6388 | Val Acc:   73.97%\n",
      "  LR: 5.00e-05\n",
      "  âœ“ Saved best model (Val Acc: 73.97%)\n",
      "\n",
      "\n",
      "âš ï¸  Early stopping triggered!\n",
      "   Validation loss hasn't improved for 10 epochs\n",
      "   Best validation accuracy: 73.97%\n",
      "   Best validation loss: 0.6039\n",
      "\n",
      "======================================================================\n",
      "Training Complete!\n",
      "Best Validation Accuracy: 73.97%\n",
      "Best Validation Loss: 0.6039\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "config = ModelConfig()  # Uses the improved config from previous cell\n",
    "model = BrainNet(config)\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function and optimizer with STRONGER REGULARIZATION\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-4, weight_decay=1e-3)  # INCREASED from 1e-5 (100x stronger!)\n",
    "\n",
    "# Learning rate scheduler - reduces LR when validation loss plateaus\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min', \n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Training hyperparameters\n",
    "num_epochs = 50\n",
    "best_val_acc = 0.0\n",
    "best_val_loss = float('inf')\n",
    "patience = 10  # Early stopping patience\n",
    "patience_counter = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Starting Training\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Number of epochs: {num_epochs}\")\n",
    "print(f\"Weight decay: 1e-3 (strong regularization)\")\n",
    "print(f\"Early stopping patience: {patience}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # ========== TRAINING PHASE ==========\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "    for batch_idx, (f_mat, c_mat, labels) in enumerate(train_pbar):\n",
    "        # Move data to device\n",
    "        f_mat = f_mat.to(device)  # [B, 400, 1632]\n",
    "        c_mat = c_mat.to(device)  # [B, 45, 54, 45]\n",
    "        labels = labels.squeeze().to(device)  # [B] - remove extra dimension\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(f_mat, c_mat)  # [B, 2]\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(logits.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        train_pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100*train_correct/train_total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_acc = 100 * train_correct / train_total\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    \n",
    "    # ========== VALIDATION PHASE ==========\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "        for f_mat, c_mat, labels in val_pbar:\n",
    "            # Move data to device\n",
    "            f_mat = f_mat.to(device)\n",
    "            c_mat = c_mat.to(device)\n",
    "            labels = labels.squeeze().to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(f_mat, c_mat)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            val_pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100*val_correct/val_total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    # Update learning rate scheduler\n",
    "    scheduler.step(avg_val_loss)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val Loss:   {avg_val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "    print(f\"  LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'train_acc': train_acc,\n",
    "        }, 'best_model.pth')\n",
    "        print(f\"  âœ“ Saved best model (Val Acc: {val_acc:.2f}%)\\n\")\n",
    "    else:\n",
    "        print()\n",
    "    \n",
    "    # Early stopping based on validation loss\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nâš ï¸  Early stopping triggered!\")\n",
    "            print(f\"   Validation loss hasn't improved for {patience} epochs\")\n",
    "            print(f\"   Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "            print(f\"   Best validation loss: {best_val_loss:.4f}\")\n",
    "            break\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Training Complete!\")\n",
    "print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"Best Validation Loss: {best_val_loss:.4f}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3572e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6dda76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Testing on Test Set\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load('best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"  Train Acc: {checkpoint['train_acc']:.2f}%\")\n",
    "print(f\"  Val Acc:   {checkpoint['val_acc']:.2f}%\")\n",
    "print()\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_pbar = tqdm(test_loader, desc=\"Testing\")\n",
    "    for f_mat, c_mat, labels in test_pbar:\n",
    "        # Move data to device\n",
    "        f_mat = f_mat.to(device)\n",
    "        c_mat = c_mat.to(device)\n",
    "        labels = labels.squeeze().to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(f_mat, c_mat)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(logits.data, 1)\n",
    "        \n",
    "        # Store predictions and labels for detailed analysis\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        test_pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100*test_correct/test_total:.2f}%'\n",
    "        })\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_acc = 100 * test_correct / test_total\n",
    "\n",
    "# Print test results\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Test Results\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Test Loss:     {avg_test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"Correct:       {test_correct}/{test_total}\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_predictions, \n",
    "                            target_names=['Class 0', 'Class 1']))\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "print(cm)\n",
    "print(f\"\\nTrue Negatives:  {cm[0,0]}\")\n",
    "print(f\"False Positives: {cm[0,1]}\")\n",
    "print(f\"False Negatives: {cm[1,0]}\")\n",
    "print(f\"True Positives:  {cm[1,1]}\")\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "class_0_acc = cm[0,0] / (cm[0,0] + cm[0,1]) * 100 if (cm[0,0] + cm[0,1]) > 0 else 0\n",
    "class_1_acc = cm[1,1] / (cm[1,0] + cm[1,1]) * 100 if (cm[1,0] + cm[1,1]) > 0 else 0\n",
    "print(f\"\\nPer-Class Accuracy:\")\n",
    "print(f\"  Class 0: {class_0_acc:.2f}%\")\n",
    "print(f\"  Class 1: {class_1_acc:.2f}%\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Testing Complete!\")\n",
    "print(f\"{'='*70}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1d1292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "5-Fold Cross-Validation Setup\n",
      "======================================================================\n",
      "Total samples: 500\n",
      "Number of folds: 5\n",
      "Runs per fold: 3\n",
      "Total training runs: 15\n",
      "\n",
      "======================================================================\n",
      "FOLD 1/5\n",
      "======================================================================\n",
      "Train samples: 388 | Test samples: 98\n",
      "  Run 1/3... âœ“ (Val Acc: 61.54%, Test Acc: 66.33%)\n",
      "  Run 2/3... âœ“ (Val Acc: 62.82%, Test Acc: 63.27%)\n",
      "  Run 3/3... âœ“ (Val Acc: 61.54%, Test Acc: 63.27%)\n",
      "\n",
      "  Fold 1 Aggregated Results:\n",
      "    Accuracy: 64.29%\n",
      "    Balanced Accuracy: 64.29%\n",
      "    Confusion Matrix:\n",
      "      True Negatives:  33\n",
      "      False Positives: 16\n",
      "      False Negatives: 19\n",
      "      True Positives:  30\n",
      "\n",
      "======================================================================\n",
      "FOLD 2/5\n",
      "======================================================================\n",
      "Train samples: 389 | Test samples: 97\n",
      "  Run 1/3... âœ“ (Val Acc: 74.36%, Test Acc: 70.10%)\n",
      "  Run 2/3... âœ“ (Val Acc: 70.51%, Test Acc: 67.01%)\n",
      "  Run 3/3... âœ“ (Val Acc: 75.64%, Test Acc: 70.10%)\n",
      "\n",
      "  Fold 2 Aggregated Results:\n",
      "    Accuracy: 70.10%\n",
      "    Balanced Accuracy: 70.07%\n",
      "    Confusion Matrix:\n",
      "      True Negatives:  36\n",
      "      False Positives: 13\n",
      "      False Negatives: 16\n",
      "      True Positives:  32\n",
      "\n",
      "======================================================================\n",
      "FOLD 3/5\n",
      "======================================================================\n",
      "Train samples: 389 | Test samples: 97\n",
      "  Run 1/3... âœ“ (Val Acc: 70.51%, Test Acc: 64.95%)\n",
      "  Run 2/3... âœ“ (Val Acc: 75.64%, Test Acc: 65.98%)\n",
      "  Run 3/3... âœ“ (Val Acc: 73.08%, Test Acc: 68.04%)\n",
      "\n",
      "  Fold 3 Aggregated Results:\n",
      "    Accuracy: 67.01%\n",
      "    Balanced Accuracy: 66.96%\n",
      "    Confusion Matrix:\n",
      "      True Negatives:  35\n",
      "      False Positives: 14\n",
      "      False Negatives: 18\n",
      "      True Positives:  30\n",
      "\n",
      "======================================================================\n",
      "FOLD 4/5\n",
      "======================================================================\n",
      "Train samples: 389 | Test samples: 97\n",
      "  Run 1/3... âœ“ (Val Acc: 62.82%, Test Acc: 60.82%)\n",
      "  Run 2/3... âœ“ (Val Acc: 60.26%, Test Acc: 65.98%)\n",
      "  Run 3/3... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "5-Fold Cross-Validation Setup\n",
      "======================================================================\n",
      "Total samples: 500\n",
      "Number of folds: 5\n",
      "Runs per fold: 3\n",
      "Total training runs: 15\n",
      "\n",
      "======================================================================\n",
      "FOLD 1/5\n",
      "======================================================================\n",
      "Train samples: 388 | Test samples: 98\n",
      "  Run 1/3... âœ“ (Val Acc: 61.54%, Test Acc: 66.33%)\n",
      "  Run 2/3... âœ“ (Val Acc: 62.82%, Test Acc: 63.27%)\n",
      "  Run 3/3... âœ“ (Val Acc: 61.54%, Test Acc: 63.27%)\n",
      "\n",
      "  Fold 1 Aggregated Results:\n",
      "    Accuracy: 64.29%\n",
      "    Balanced Accuracy: 64.29%\n",
      "    Confusion Matrix:\n",
      "      True Negatives:  33\n",
      "      False Positives: 16\n",
      "      False Negatives: 19\n",
      "      True Positives:  30\n",
      "\n",
      "======================================================================\n",
      "FOLD 2/5\n",
      "======================================================================\n",
      "Train samples: 389 | Test samples: 97\n",
      "  Run 1/3... âœ“ (Val Acc: 74.36%, Test Acc: 70.10%)\n",
      "  Run 2/3... âœ“ (Val Acc: 70.51%, Test Acc: 67.01%)\n",
      "  Run 3/3... âœ“ (Val Acc: 75.64%, Test Acc: 70.10%)\n",
      "\n",
      "  Fold 2 Aggregated Results:\n",
      "    Accuracy: 70.10%\n",
      "    Balanced Accuracy: 70.07%\n",
      "    Confusion Matrix:\n",
      "      True Negatives:  36\n",
      "      False Positives: 13\n",
      "      False Negatives: 16\n",
      "      True Positives:  32\n",
      "\n",
      "======================================================================\n",
      "FOLD 3/5\n",
      "======================================================================\n",
      "Train samples: 389 | Test samples: 97\n",
      "  Run 1/3... âœ“ (Val Acc: 70.51%, Test Acc: 64.95%)\n",
      "  Run 2/3... âœ“ (Val Acc: 75.64%, Test Acc: 65.98%)\n",
      "  Run 3/3... âœ“ (Val Acc: 73.08%, Test Acc: 68.04%)\n",
      "\n",
      "  Fold 3 Aggregated Results:\n",
      "    Accuracy: 67.01%\n",
      "    Balanced Accuracy: 66.96%\n",
      "    Confusion Matrix:\n",
      "      True Negatives:  35\n",
      "      False Positives: 14\n",
      "      False Negatives: 18\n",
      "      True Positives:  30\n",
      "\n",
      "======================================================================\n",
      "FOLD 4/5\n",
      "======================================================================\n",
      "Train samples: 389 | Test samples: 97\n",
      "  Run 1/3... âœ“ (Val Acc: 62.82%, Test Acc: 60.82%)\n",
      "  Run 2/3... âœ“ (Val Acc: 60.26%, Test Acc: 65.98%)\n",
      "  Run 3/3... "
     ]
    },
    {
     "ename": "error",
     "evalue": "Error -3 while decompressing data: incorrect data check",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 116\u001b[39m\n\u001b[32m    113\u001b[39m train_correct = \u001b[32m0\u001b[39m\n\u001b[32m    114\u001b[39m train_total = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_run_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf_mat\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_mat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mc_mat\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_mat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/storage1/shourovj/shourovj_works/Auburn/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/storage1/shourovj/shourovj_works/Auburn/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/storage1/shourovj/shourovj_works/Auburn/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/storage1/shourovj/shourovj_works/Auburn/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mMRIDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     17\u001b[39m label = row[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Load .mat files\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m f_data = \u001b[43msio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m f_mat = f_data[\u001b[33m'\u001b[39m\u001b[33mfeature_mat\u001b[39m\u001b[33m'\u001b[39m]  \u001b[38;5;66;03m# Shape: (400, 1632) - ROI features\u001b[39;00m\n\u001b[32m     22\u001b[39m c_data = sio.loadmat(\u001b[38;5;28mself\u001b[39m.data_dir + cluster_file)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/storage1/shourovj/shourovj_works/Auburn/.venv/lib/python3.11/site-packages/scipy/io/matlab/_mio.py:235\u001b[39m, in \u001b[36mloadmat\u001b[39m\u001b[34m(file_name, mdict, appendmat, spmatrix, **kwargs)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    234\u001b[39m     MR, _ = mat_reader_factory(f, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     matfile_dict = \u001b[43mMR\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spmatrix:\n\u001b[32m    237\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m issparse, coo_matrix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/storage1/shourovj/shourovj_works/Auburn/.venv/lib/python3.11/site-packages/scipy/io/matlab/_mio5.py:333\u001b[39m, in \u001b[36mMatFile5Reader.get_variables\u001b[39m\u001b[34m(self, variable_names)\u001b[39m\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m     res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_var_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MatReadError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    335\u001b[39m     warnings.warn(\n\u001b[32m    336\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUnreadable variable \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m, because \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    337\u001b[39m         \u001b[38;5;167;01mWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/storage1/shourovj/shourovj_works/Auburn/.venv/lib/python3.11/site-packages/scipy/io/matlab/_mio5.py:291\u001b[39m, in \u001b[36mMatFile5Reader.read_var_array\u001b[39m\u001b[34m(self, header, process)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_var_array\u001b[39m(\u001b[38;5;28mself\u001b[39m, header, process=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    275\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m''' Read array, given `header`\u001b[39;00m\n\u001b[32m    276\u001b[39m \n\u001b[32m    277\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    289\u001b[39m \u001b[33;03m       `process`.\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_matrix_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray_from_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mscipy/io/matlab/_mio5_utils.pyx:665\u001b[39m, in \u001b[36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mscipy/io/matlab/_mio5_utils.pyx:694\u001b[39m, in \u001b[36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mscipy/io/matlab/_mio5_utils.pyx:768\u001b[39m, in \u001b[36mscipy.io.matlab._mio5_utils.VarReader5.read_real_complex\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mscipy/io/matlab/_mio5_utils.pyx:445\u001b[39m, in \u001b[36mscipy.io.matlab._mio5_utils.VarReader5.read_numeric\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mscipy/io/matlab/_mio5_utils.pyx:350\u001b[39m, in \u001b[36mscipy.io.matlab._mio5_utils.VarReader5.read_element\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mscipy/io/matlab/_streams.pyx:171\u001b[39m, in \u001b[36mscipy.io.matlab._streams.ZlibInputStream.read_string\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mscipy/io/matlab/_streams.pyx:147\u001b[39m, in \u001b[36mscipy.io.matlab._streams.ZlibInputStream.read_into\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mscipy/io/matlab/_streams.pyx:134\u001b[39m, in \u001b[36mscipy.io.matlab._streams.ZlibInputStream._fill_buffer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31merror\u001b[39m: Error -3 while decompressing data: incorrect data check"
     ]
    }
   ],
   "source": [
    "## 5-Fold Cross-Validation with Repeated Runs\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Configuration\n",
    "NUM_FOLDS = 5\n",
    "NUM_RUNS_PER_FOLD = 3  # Repeat each fold this many times\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Prepare data\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"5-Fold Cross-Validation Setup\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Number of folds: {NUM_FOLDS}\")\n",
    "print(f\"Runs per fold: {NUM_RUNS_PER_FOLD}\")\n",
    "print(f\"Total training runs: {NUM_FOLDS * NUM_RUNS_PER_FOLD}\")\n",
    "\n",
    "# Read full dataframe\n",
    "df_full = pd.read_csv('data_split/data_clean.csv')\n",
    "X = df_full[['feature', 'cluster']].values\n",
    "y = df_full['label'].values\n",
    "\n",
    "# Storage for results\n",
    "cv_results = {\n",
    "    'fold': [],\n",
    "    'run': [],\n",
    "    'train_acc': [],\n",
    "    'val_acc': [],\n",
    "    'test_acc': [],\n",
    "    'training_loss': []\n",
    "}\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "fold_idx = 0\n",
    "all_fold_accuracies = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "    fold_idx += 1\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"FOLD {fold_idx}/{NUM_FOLDS}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Train samples: {len(train_idx)} | Test samples: {len(test_idx)}\")\n",
    "    \n",
    "    # Get fold data\n",
    "    X_train_fold, X_test_fold = X[train_idx], X[test_idx]\n",
    "    y_train_fold, y_test_fold = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # CRITICAL FIX: Convert labels to 0-indexed (MRIDataset does label - 1)\n",
    "    y_test_fold = y_test_fold - 1\n",
    "    \n",
    "    # Further split train into train/val for this fold\n",
    "    train_val_idx = np.arange(len(X_train_fold))\n",
    "    y_temp = y_train_fold\n",
    "    \n",
    "    skf_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    \n",
    "    fold_predictions = []  # Store predictions from all runs for this fold\n",
    "    fold_train_losses = []\n",
    "    \n",
    "    # Run multiple times for this fold\n",
    "    for run in range(NUM_RUNS_PER_FOLD):\n",
    "        print(f\"  Run {run+1}/{NUM_RUNS_PER_FOLD}...\", end=\" \", flush=True)\n",
    "        \n",
    "        # Use first split from inner CV for train/val\n",
    "        train_indices, val_indices = list(skf_inner.split(train_val_idx, y_temp))[0]\n",
    "        \n",
    "        train_fold_idx = train_idx[train_indices]\n",
    "        val_fold_idx = train_idx[val_indices]\n",
    "        \n",
    "        # Create datasets for this run\n",
    "        train_run_df = df_full.iloc[train_fold_idx].reset_index(drop=True)\n",
    "        val_run_df = df_full.iloc[val_fold_idx].reset_index(drop=True)\n",
    "        test_run_df = df_full.iloc[test_idx].reset_index(drop=True)\n",
    "        \n",
    "        # Create datasets\n",
    "        train_run_dataset = MRIDataset(data_dir, train_run_df)\n",
    "        val_run_dataset = MRIDataset(data_dir, val_run_df)\n",
    "        test_run_dataset = MRIDataset(data_dir, test_run_df)\n",
    "        \n",
    "        # Create dataloaders\n",
    "        train_run_loader = data.DataLoader(train_run_dataset, batch_size=16, shuffle=True)\n",
    "        val_run_loader = data.DataLoader(val_run_dataset, batch_size=16, shuffle=False)\n",
    "        test_run_loader = data.DataLoader(test_run_dataset, batch_size=16, shuffle=False)\n",
    "        \n",
    "        # Initialize model\n",
    "        config = ModelConfig()\n",
    "        model_run = BrainNet(config)\n",
    "        model_run = model_run.to(device)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = Adam(model_run.parameters(), lr=1e-4, weight_decay=1e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6\n",
    "        )\n",
    "        \n",
    "        # Train\n",
    "        best_val_acc = 0.0\n",
    "        best_val_loss = float('inf')\n",
    "        best_model_state = None\n",
    "        patience = 10\n",
    "        patience_counter = 0\n",
    "        best_train_loss = float('inf')\n",
    "        \n",
    "        for epoch in range(50):\n",
    "            # Training\n",
    "            model_run.train()\n",
    "            train_loss = 0.0\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            \n",
    "            for f_mat, c_mat, labels in train_run_loader:\n",
    "                f_mat = f_mat.to(device)\n",
    "                c_mat = c_mat.to(device)\n",
    "                labels = labels.view(-1).to(device)  # FIX: use view instead of squeeze\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                logits = model_run(f_mat, c_mat)\n",
    "                loss = criterion(logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(logits.data, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            avg_train_loss = train_loss / len(train_run_loader)\n",
    "            train_acc = 100 * train_correct / train_total\n",
    "            \n",
    "            # Validation\n",
    "            model_run.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for f_mat, c_mat, labels in val_run_loader:\n",
    "                    f_mat = f_mat.to(device)\n",
    "                    c_mat = c_mat.to(device)\n",
    "                    labels = labels.view(-1).to(device)  # FIX: use view instead of squeeze\n",
    "                    \n",
    "                    logits = model_run(f_mat, c_mat)\n",
    "                    loss = criterion(logits, labels)\n",
    "                    \n",
    "                    _, predicted = torch.max(logits.data, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "                    val_loss += loss.item()\n",
    "            \n",
    "            avg_val_loss = val_loss / len(val_run_loader)\n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            \n",
    "            scheduler.step(avg_val_loss)\n",
    "            \n",
    "            # Save best model\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_train_loss = avg_train_loss\n",
    "                best_model_state = model_run.state_dict().copy()\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    break\n",
    "        \n",
    "        # Load best model and evaluate on test\n",
    "        model_run.load_state_dict(best_model_state)\n",
    "        model_run.eval()\n",
    "        \n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        run_predictions = []\n",
    "        run_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for f_mat, c_mat, labels in test_run_loader:\n",
    "                f_mat = f_mat.to(device)\n",
    "                c_mat = c_mat.to(device)\n",
    "                labels = labels.view(-1).to(device)  # FIX: use view instead of squeeze\n",
    "                \n",
    "                logits = model_run(f_mat, c_mat)\n",
    "                loss = criterion(logits, labels)\n",
    "                \n",
    "                _, predicted = torch.max(logits.data, 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                run_predictions.extend(predicted.cpu().numpy())\n",
    "                run_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        test_acc = 100 * test_correct / test_total\n",
    "        \n",
    "        # Store results\n",
    "        cv_results['fold'].append(fold_idx)\n",
    "        cv_results['run'].append(run + 1)\n",
    "        cv_results['train_acc'].append(train_acc)\n",
    "        cv_results['val_acc'].append(best_val_acc)\n",
    "        cv_results['test_acc'].append(test_acc)\n",
    "        cv_results['training_loss'].append(best_train_loss)\n",
    "        \n",
    "        fold_predictions.append(np.array(run_predictions))\n",
    "        fold_train_losses.append(best_train_loss)\n",
    "        \n",
    "        print(f\"âœ“ (Val Acc: {best_val_acc:.2f}%, Test Acc: {test_acc:.2f}%)\")\n",
    "    \n",
    "    # Aggregate predictions for this fold by majority vote\n",
    "    fold_predictions = np.array(fold_predictions)  # [NUM_RUNS, num_test_samples]\n",
    "    num_test_samples = fold_predictions.shape[1]\n",
    "    fold_majority_pred = np.zeros(num_test_samples, dtype=int)\n",
    "    \n",
    "    for sample_idx in range(num_test_samples):\n",
    "        sample_preds = fold_predictions[:, sample_idx]\n",
    "        unique, counts = np.unique(sample_preds, return_counts=True)\n",
    "        max_count = np.max(counts)\n",
    "        max_indices = np.where(counts == max_count)[0]\n",
    "        \n",
    "        if len(max_indices) == 1:\n",
    "            fold_majority_pred[sample_idx] = unique[max_indices[0]]\n",
    "        else:\n",
    "            tied_classes = unique[max_indices]\n",
    "            best_run_idx = None\n",
    "            best_loss = float('inf')\n",
    "            \n",
    "            for run_idx in range(NUM_RUNS_PER_FOLD):\n",
    "                if sample_preds[run_idx] in tied_classes and fold_train_losses[run_idx] < best_loss:\n",
    "                    best_loss = fold_train_losses[run_idx]\n",
    "                    best_run_idx = run_idx\n",
    "            \n",
    "            if best_run_idx is not None:\n",
    "                fold_majority_pred[sample_idx] = sample_preds[best_run_idx]\n",
    "    \n",
    "    # Calculate fold accuracy\n",
    "    fold_accuracy = accuracy_score(y_test_fold, fold_majority_pred)\n",
    "    fold_balanced_acc = balanced_accuracy_score(y_test_fold, fold_majority_pred)\n",
    "    cm = confusion_matrix(y_test_fold, fold_majority_pred)\n",
    "    \n",
    "    print(f\"\\n  Fold {fold_idx} Aggregated Results:\")\n",
    "    print(f\"    Accuracy: {fold_accuracy*100:.2f}%\")\n",
    "    print(f\"    Balanced Accuracy: {fold_balanced_acc*100:.2f}%\")\n",
    "    print(f\"    Confusion Matrix:\")\n",
    "    print(f\"      True Negatives:  {cm[0,0]}\")\n",
    "    print(f\"      False Positives: {cm[0,1]}\")\n",
    "    print(f\"      False Negatives: {cm[1,0]}\")\n",
    "    print(f\"      True Positives:  {cm[1,1]}\")\n",
    "    \n",
    "    all_fold_accuracies.append(fold_accuracy * 100)\n",
    "\n",
    "# Print cross-validation summary\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"5-Fold Cross-Validation Summary\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "cv_df['test_acc_rounded'] = cv_df['test_acc'].round(2)\n",
    "\n",
    "print(f\"\\nResults by Fold and Run:\")\n",
    "print(cv_df[['fold', 'run', 'train_acc', 'val_acc', 'test_acc_rounded']])\n",
    "\n",
    "print(f\"\\nAggregate Results by Fold:\")\n",
    "for fold in range(1, NUM_FOLDS + 1):\n",
    "    fold_accs = cv_df[cv_df['fold'] == fold]['test_acc'].values\n",
    "    print(f\"  Fold {fold}: {fold_accs.mean():.2f}% Â± {fold_accs.std():.2f}% (Individual runs)\")\n",
    "\n",
    "print(f\"\\nAggregated (Majority Vote) Results by Fold:\")\n",
    "for fold_idx, fold_acc in enumerate(all_fold_accuracies, 1):\n",
    "    print(f\"  Fold {fold_idx}: {fold_acc:.2f}%\")\n",
    "\n",
    "overall_mean_individual = cv_df['test_acc'].mean()\n",
    "overall_std_individual = cv_df['test_acc'].std()\n",
    "overall_mean_aggregated = np.mean(all_fold_accuracies)\n",
    "overall_std_aggregated = np.std(all_fold_accuracies)\n",
    "\n",
    "print(f\"\\nOverall Accuracy (Individual Runs): {overall_mean_individual:.2f}% Â± {overall_std_individual:.2f}%\")\n",
    "print(f\"Overall Accuracy (Aggregated): {overall_mean_aggregated:.2f}% Â± {overall_std_aggregated:.2f}%\")\n",
    "\n",
    "# Save results\n",
    "cv_df.to_csv('cv_results_5fold.csv', index=False)\n",
    "print(f\"\\nâœ“ Cross-validation results saved to 'cv_results_5fold.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "76ff2beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Cross-validation results saved to 'cv_results_5fold.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "cv_df.to_csv('cv_results_5fold.csv', index=False)\n",
    "print(f\"\\nâœ“ Cross-validation results saved to 'cv_results_5fold.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "35cecb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df = pd.DataFrame(cv_results)\n",
    "cv_df['test_acc_rounded'] = cv_df['test_acc'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9aeadf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_566948/3255238608.py:13: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  axes[0].boxplot(fold_accs, labels=[f'Fold {i}' for i in range(1, 6)])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (4), usually from a call to set_ticks, does not match the number of labels (5).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m axes[\u001b[32m1\u001b[39m].set_title(\u001b[33m'\u001b[39m\u001b[33mAverage Accuracy by Fold\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     29\u001b[39m axes[\u001b[32m1\u001b[39m].set_xticks(x)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_xticklabels\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mFold \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m axes[\u001b[32m1\u001b[39m].legend()\n\u001b[32m     32\u001b[39m axes[\u001b[32m1\u001b[39m].grid(axis=\u001b[33m'\u001b[39m\u001b[33my\u001b[39m\u001b[33m'\u001b[39m, alpha=\u001b[32m0.3\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/storage1/shourovj/shourovj_works/Auburn/.venv/lib/python3.11/site-packages/matplotlib/axes/_base.py:74\u001b[39m, in \u001b[36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/storage1/shourovj/shourovj_works/Auburn/.venv/lib/python3.11/site-packages/matplotlib/axis.py:2106\u001b[39m, in \u001b[36mAxis.set_ticklabels\u001b[39m\u001b[34m(self, labels, minor, fontdict, **kwargs)\u001b[39m\n\u001b[32m   2102\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(locator, mticker.FixedLocator):\n\u001b[32m   2103\u001b[39m     \u001b[38;5;66;03m# Passing [] as a list of labels is often used as a way to\u001b[39;00m\n\u001b[32m   2104\u001b[39m     \u001b[38;5;66;03m# remove all tick labels, so only error for > 0 labels\u001b[39;00m\n\u001b[32m   2105\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(locator.locs) != \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels) != \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2106\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2107\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe number of FixedLocator locations\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2108\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(locator.locs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m), usually from a call to\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2109\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m set_ticks, does not match\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2110\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m the number of labels (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2111\u001b[39m     tickd = {loc: lab \u001b[38;5;28;01mfor\u001b[39;00m loc, lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(locator.locs, labels)}\n\u001b[32m   2112\u001b[39m     func = functools.partial(\u001b[38;5;28mself\u001b[39m._format_with_dict, tickd)\n",
      "\u001b[31mValueError\u001b[39m: The number of FixedLocator locations (4), usually from a call to set_ticks, does not match the number of labels (5)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualize 5-Fold CV Results\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cv_df = pd.read_csv('cv_results_5fold.csv')\n",
    "\n",
    "# Box plot of test accuracy by fold\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Test accuracy distribution by fold\n",
    "fold_accs = [cv_df[cv_df['fold'] == f]['test_acc'].values for f in range(1, 6)]\n",
    "axes[0].boxplot(fold_accs, labels=[f'Fold {i}' for i in range(1, 6)])\n",
    "axes[0].set_ylabel('Test Accuracy (%)')\n",
    "axes[0].set_title('Test Accuracy Distribution by Fold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Train vs Val vs Test accuracy\n",
    "fold_means = cv_df.groupby('fold')[['train_acc', 'val_acc', 'test_acc']].mean()\n",
    "x = np.arange(len(fold_means))\n",
    "width = 0.25\n",
    "\n",
    "axes[1].bar(x - width, fold_means['train_acc'], width, label='Train', alpha=0.8)\n",
    "axes[1].bar(x, fold_means['val_acc'], width, label='Val', alpha=0.8)\n",
    "axes[1].bar(x + width, fold_means['test_acc'], width, label='Test', alpha=0.8)\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_xlabel('Fold')\n",
    "axes[1].set_title('Average Accuracy by Fold')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels([f'Fold {i}' for i in range(1, 6)])\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cv_results_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Visualization saved to 'cv_results_visualization.png'\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Cross-Validation Statistics\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nTrain Accuracy:  {cv_df['train_acc'].mean():.2f}% Â± {cv_df['train_acc'].std():.2f}%\")\n",
    "print(f\"Val Accuracy:    {cv_df['val_acc'].mean():.2f}% Â± {cv_df['val_acc'].std():.2f}%\")\n",
    "print(f\"Test Accuracy:   {cv_df['test_acc'].mean():.2f}% Â± {cv_df['test_acc'].std():.2f}%\")\n",
    "\n",
    "print(f\"\\nPer-Fold Test Accuracy:\")\n",
    "for fold in range(1, 6):\n",
    "    fold_accs = cv_df[cv_df['fold'] == fold]['test_acc'].values\n",
    "    print(f\"  Fold {fold}: {fold_accs.mean():.2f}% Â± {fold_accs.std():.2f}% (min: {fold_accs.min():.2f}%, max: {fold_accs.max():.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0acc8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f79e5c13dd0>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUztJREFUeJzt3Xl4VOX9/vH3zGQjOyFkJRD2RSHRABEQRYmgWBRX6gbl64pI1fzaKlqh1lasVqUKFbVuVVHUYl2qqERxgQgKsu9hSVgSEiA72Wbm98dJAgECGUhyZib367rOlZmTc2Y+GYbMnec8i8XpdDoRERERMYnV7AJERESkbVMYEREREVMpjIiIiIipFEZERETEVAojIiIiYiqFERERETGVwoiIiIiYSmFERERETOVjdgFN4XA42Lt3LyEhIVgsFrPLERERkSZwOp2UlJQQFxeH1dp4+4dHhJG9e/eSkJBgdhkiIiJyGnJycujUqVOj3/eIMBISEgIYP0xoaKjJ1YiIiEhTFBcXk5CQUP853hiPCCN1l2ZCQ0MVRkRERDzMqbpYqAOriIiImEphREREREylMCIiIiKmOq0wMmfOHBITEwkICCA1NZXly5ef9PhZs2bRu3dv2rVrR0JCAvfffz8VFRWnVbCIiIh4F5fDyPz580lPT2fGjBmsXLmSpKQkRo8ezf79+094/Lx583jwwQeZMWMGGzdu5JVXXmH+/Pk89NBDZ1y8iIiIeD6Xw8gzzzzD7bffzqRJk+jXrx9z584lMDCQV1999YTHL126lGHDhnHjjTeSmJjIqFGjuOGGG07ZmiIiIiJtg0thpKqqihUrVpCWlnbkAaxW0tLSyMzMPOE5Q4cOZcWKFfXhY/v27Xz22WeMGTOm0eeprKykuLi4wSYiIiLeyaV5RgoKCrDb7URHRzfYHx0dzaZNm054zo033khBQQHnn38+TqeTmpoa7rrrrpNeppk5cyaPPvqoK6WJiIiIh2rx0TSLFy/m8ccf55///CcrV65kwYIF/O9//+Oxxx5r9Jxp06ZRVFRUv+Xk5LR0mSIiImISl1pGIiMjsdls5OXlNdifl5dHTEzMCc955JFHuOWWW7jtttsA6N+/P2VlZdxxxx08/PDDJ1w4x9/fH39/f1dKExEREQ/lUsuIn58fKSkpZGRk1O9zOBxkZGQwZMiQE55TXl5+XOCw2WyAsZqfiIiItG0ur02Tnp7OxIkTGThwIIMHD2bWrFmUlZUxadIkACZMmEB8fDwzZ84EYOzYsTzzzDOcc845pKamsm3bNh555BHGjh1bH0pERESk7XI5jIwfP578/HymT59Obm4uycnJLFy4sL5Ta3Z2doOWkD/+8Y9YLBb++Mc/smfPHjp27MjYsWP561//2nw/xWlwOJx8uSGPd5Zn88LN5xLo5xFrBoqIiHgdi9MDrpUUFxcTFhZGUVFRs63aW2N3cPHT35J9sJw/je3Hb4Z1bZbHFREREUNTP7/b7No0PjYrd1zQDYCXv99Btd1hckUiIiJtU5sNIwDXpnQiMtifPYWH+WT1XrPLERERaZPadBgJ8LXxf+cnAjD32ywcDre/YiUiIuJ12nQYAbj5vC6E+PuwJa+UrzedeLE/ERERaTltPoyEBvhy43mdAaN1RERERFpXmw8jALcO64qfzcrPuw7x086DZpcjIiLSpiiMAFGhAVyT0gmAFxardURERKQ1KYzUuvOCblgt8PWm/WzcV2x2OSIiIm2GwkitxMggLusfC8CL6jsiIiLSahRGjjL5wu4AfLJmHzkHy02uRkREpG1QGDnK2fFhDO8Zid3h5F/fbze7HBERkTZBYeQYda0j7/6UQ0FppcnViIiIeD+FkWMM6d6BpE5hVNY4eGPpTrPLERER8XoKI8ewWCxMHmG0jryxdCellTUmVyQiIuLdFEZOYFS/GLp1DKK4ooZ3lmWbXY6IiIhXUxg5AavVwl0XGK0j//phO5U1dpMrEhER8V4KI4248pw4okP9ySuu5L+/7DG7HBEREa+lMNIIfx8bt53fDYAXv9uO3eE0uSIRERHvpDByEjekdiY0wIft+WV8tSHX7HJERES8ksLISQT7+zBxaCJgLKDndKp1REREpLkpjJzCb4YmEuBrZfXuIjKzDphdjoiIiNdRGDmFDsH+jB+YAMALWkCvbXI64X//D/57N1SVmV2NiIjXURhpgtuGd8NmtfD91gLW7i4yuxxpbdsy4Kd/waq34c2r4HCh2RWJiHgVhZEmSIgIZOyAWADmfqfWkTbnh2eO3M5ZBm/8CkrzzatHRMTLKIw00V21U8R/vnYfOwrUVN9mZP8Iu5aA1Rdu+gCCOkLuWnjtUijabXZ1IiJeQWGkifrEhHJxnygcTnjpu+1mlyOt5fvaVpHkG6HnJfB/X0BYAhzYBq9eCgXbzK1PRMQLKIy4oG4Bvf+s2M3+4gqTq5EWl7sWtn4BFisMu9fY16E7TPocOvSAohyjhSR3nbl1ioh4OIURFwxKjGBgl/ZU2R28smSH2eVIS/vhWePrWVcZIaROeAJMWggx/aEsH14fAznLzalRRMQLKIy4qK515O0fsyk6XG1yNdJiDmTB+g+N2+fff/z3gzvCxE8hIRUqiuDf4yDrm1YtUUTEWyiMuOii3lH0ig6mtLKGt37cZXY50lKW/AOcDug52mgBOZF24XDLh9DtIqgug3nXw8ZPW7VMERFvoDDiIqvVwl0XGq0jry3ZSUW13eSKpNkV74VV84zbw9NPfqxfENw4H/qOBXsVvDcBVr/b8jWKiHgRhZHTMDYpjvjwdhSUVvLBCg3v9DqZc8BRDV2GQefzTn28jz9c+zok3wROO3x4Jyx/ucXLFBHxFgojp8HXZuX24V0BY5hvjd1hckXSbMoPws+vGbfPP0WryNFsPnDFbEi9y7j/2e/gu78bU8mLiMhJKYycpvGDOhMR5Ef2wXI+W5drdjnSXJa9aPT/iBkAPUa6dq7VCpc+ARc+YNz/+jH4aroCiYjIKSiMnKZ2fjZ+MzQRgBcWZ+HUB47nqyyBZXON28PTwWJx/TEsFrjoIRj1V+P+0ufg0/vAob5FIiKNURg5AxOGdCHQz8bGfcV8tlatIx5vxetQUWhMaNb3ijN7rKH3wNjnAIvxuAtuB7uGgouInMhphZE5c+aQmJhIQEAAqampLF/e+IRPI0aMwGKxHLddfvnlp120uwgP9OOGwZ0BmDJvJb95bTkrdh0yuSo5LTWVsHS2cXvYfWC1nfljpkyEa18Fqw+s+w+8exNUHz7zxxUR8TIuh5H58+eTnp7OjBkzWLlyJUlJSYwePZr9+/ef8PgFCxawb9+++m3dunXYbDauu+66My7eHaRf0otrzu2EzWph8eZ8rnlhKbe8sozlOw6aXZq4YtU8KM2F0HgYML75Hvfsq+HX74BPgDG1/FvXQpUWWhQROZrF6WJnh9TUVAYNGsTs2cZfkQ6Hg4SEBKZOncqDDz54yvNnzZrF9OnT2bdvH0FBQU16zuLiYsLCwigqKiI0NNSVck9u6fNQvA8iexhN8x16QkjMafUV2FlQxj8Xb2PByj3UOIyX9LxuEfx2ZE+GdOuA5XT6H0jrsNfA7IFwaIfRAfW8yc3/HDuXwLzxUFUCIx6CEQ80/3OIiLiZpn5+uxRGqqqqCAwM5IMPPmDcuHH1+ydOnEhhYSEfffTRKR+jf//+DBkyhJdeeqnRYyorK6msrKy/X1xcTEJCQvOHkZdGwN5fGu7zCzbWIenQEyJ71oaU2s0/+JQPmXOwnBe+zeL9n3Oothsv7aDE9ky9uCfDe0YqlLijtR/Af26FdhFw/zpjIrOWfJ7ADnD/evBt1zLPIyLiJpoaRnxcedCCggLsdjvR0dEN9kdHR7Np06ZTnr98+XLWrVvHK6+8ctLjZs6cyaOPPupKaadn8J3GyqwHthpLwh/aCVWlsG+1sR0rJM4IKpE9jbDSoYfRqhLepb6PQUJEII9f1Z97LurB3G+zePenHH7aeYgJry4nOSGce0f2ZETvjgol7sLphO+fMW6fd3fLBRGAfuMg41EozIZVb8Og21ruuUREPIhLLSN79+4lPj6epUuXMmTIkPr9f/jDH/j2229ZtmzZSc+/8847yczMZM2aNSc9rtVaRo5VU2U01RfUhpMDW6Gg9mv5gcbPs/pCaKwRVkJiILT2a0gsB20dmLehmlfWHOZQtR8A/ePDmHpxDy7pF61QYrbNC+Gd8UaL2P3roF37ln2+ZS/C53+A9l1h6orm6SgrIuKmWqRlJDIyEpvNRl5eXoP9eXl5xMTEnPTcsrIy3n33Xf785z+f8nn8/f3x9/d3pbTm4eMHHXsb27HKDxoruR7YelRY2Wbss1caf+0WZh93WgRwD3CPDSr8gthTE8a+/e3Je7c97wXF0L93b/r06oU1NB5CoiE42pheXFqe0wnfP23cHnRrywcRgHNuhsUzjdC76VPod2XLP6eIiJtzKYz4+fmRkpJCRkZGfZ8Rh8NBRkYG99xzz0nPff/996msrOTmm28+7WJNFRhhbAmDGu532KF4j7G4Wsk+KMmtvZ1be3+f0Um2uowAexndLWV0t+01zq0AVtduRwsIN1pWgmvDSUg0BMccczsKAsJOb2IuMexaAruXg80fzpvSOs/pF2RcnvnuKWNl4L5X6N9QRNo8l8IIQHp6OhMnTmTgwIEMHjyYWbNmUVZWxqRJkwCYMGEC8fHxzJw5s8F5r7zyCuPGjaNDhw7NU7m7sNogvLOxnUxFcYOAcvjgbjZu2ULBvp10cBwk2nKIaEshvtQYE29VFEL+Kfrh+AQYoSQ45kirSnC00UEyKBICI498bdfemK5cjqjrK3LOzcbr11oG3wlLnoM9K2DXUkgc1nrPLSLihlwOI+PHjyc/P5/p06eTm5tLcnIyCxcurO/Ump2djfWYD73Nmzfzww8/8OWXXzZP1Z4oINTYOvYCoB1w7kVQdLiafy/dycvfb6e4oppB0Vb+dXUnwmoOQOl+Y+6LkjwoPWoryYPKIqipaPTy0HEsVmO0SFCkEVaOCyzH3A+O9u6/2Pf+AlkZYLHBsN+27nMHd4TkG2HFa0briMKIiLRxLs8zYoYWm2fEjWzbX8KvX1pGQWklfWNDefu2VCKC/Bo/ofrwkWBSH1JyoWw/lB2A8gIoKzC+VhS5XlBwDCSeD12HQ+JwiOjmXeHkvQmw4SNjgrOrGx9m3mIOZMHzKYAT7l4GUX1avwYRkRbWIvOMmKUthBE4jUDSVPZqowPu0QGl7IAxQqh+34Ej3ys/AE5Hw8cIiTPCSV1Aad/Vc8NJ/haYMxgjCPwIUX3NqWP+zbDxE0i+GcbNMacGEZEWpDDioY4NJPNuS6V9cwQSV1RXwJ6fYcf3sPMHo5OnvarhMaHxRotJXUBpn+g54eS/U2DVW9D7crhhnnl15PwEr6QZQ8PvW2MMCRcR8SIKIx7MLQLJ0aoPw+6fjgonP4HjmBVowxJqg0ltQGnfxZxaT6UwB55LBkcN3JYBnQaaW8+rl0H2Uhh2L1xy6mHvIiKeRGHEw7ldIDlaVbnRWlIXTvb8bHy4Hy28M3Q5H7oMgc5DjNlq3aHl5PMHYNlc6HoBTPzE7Gpg8+fwzq/BP9SYIj6gbby/RaRtUBjxAm4dSI5WVQY5y4xgsuN72Lvy+HAS1BE6nwedhxoBJbo/2FwezHVmygrg2bOh5jDc8l/oflHrPv+JOBzwz/OgYDNc8ljrj+wREWlBCiNeYmteCTe87AGB5GiVpZDzozGHRvaPsPtnY5bao/kFQ6dB0GWo0XLSaWDLLxyX8Rh8/3eIOxdu/9o9WmoAVr4JH99jdBK+d7UxE7CIiBdQGPEiRweSfrWjbNw+kBytptKY12PXUsjOhOxlxjwpR7P6Qtw5RutJl6GQkGrMeNtcKoqNVpHKIhj/FvQd23yPfaZqKmHWAGNOmXEvGHOQiIh4AYURL+PxgeRoDjvs32C0mtQFlJJ9xx8X1c8IJXHJEDPAuO8bcHrP+cOzsOhPENnbGM7rbrPR1tXXsS/cnek+rTYiImdAYcQLeVUgOZrTCYd2GqGk7tLOga3HH2f1McJE7AAjnMQmQUz/U3f6rD5stDyU7YdxcyH5hhb5Mc7I4UJ49iyoKoUb34deo8yuSETkjCmMeCmvDSTHKs03wsnunyB3DexbDYcPnfjY9l2PCSgDGq41s/xl+Ox3ENYZfrsSbL6t8zO46ouHIXO2MTz6N5+aXY2IyBlTGPFiRiD5kYLSKu8OJEdzOqFod20wWXPka/HuEx8fHF0bTgbAmvegKAfG/B0G3966dbuiaDf8I8kYiXT71xCfYnZFLa+swLg81W0E9L/W7GpEpJkpjHi5owPJWXFGIAkP9PJAciJlB4xgcnRIKdgKHPO2DuoI961t+RE7Z2rBnbDmXeg3Dq5/w+xqWpbTCfOuh621C2i6e1gUEZcpjLQBCiSNqCqDvPXGpZ3cNcaidKl3Qr8rza7s1PLWwwtDjVWWp64wFij0VnWXz7BQHx4v/Rucd5eZVYlIM1IYaSMUSLzQW9fAtkUw6Da4/Gmzq2kZ+zfCSyOgpsIIIKW5xogigNEzYcjdppYnIs2jqZ/fbja+UVzVMzqEd24/j8hgP9bvLebGl5exKbfY7LLkTAy71/j6y9vGZShvU10B/7nNCCI90oxWq5EzYPj/M77/xTRY+ry5NXoLe/WpjxFxAwojXuDoQLJhXzGXzvqeKW+vZEteidmlyelIHA6xyca09T+9bHY1zS/jz5C3DgIjjUneLBZju/gRuOAPxjFf/hF+mGVqmR7L6YQd38EbY+GvMfD908Y+ETemMOIlekaHsGDyMC7vHwvA/9buY/Ss77hn3kq2KpR4FovlyBo1y140Fib0Ftsy4Mc5xu1x/4TgqCPfs1jg4odhxDTj/qIZ8P0zrV+jp3I6YesiePVSI4js+M4YmZXxZ/j8D8ZkgyJuSn1GvNCm3GL+sWgrn6/LBYzf8WMHxPHbkT3pERVscnXSJPYaeP5cKNzlPaNMyg7AC0OgNA8G3Q6X/73xY799Er75q3H74j/CBb9vnRo9kcMBmz+D756CfauMfTZ/SJloDHH/+i+A0+jAfdVLpz+LschpUAdWYcPeYv6RsYUv1ucBYLXAFUlGKOnWUaHE7S17CT7/PbRPhKkrwWozu6LT53TCuzcaH5qRveHOb089zPq7p2o/SIERD8GIB1q+Tk/isMOG/8J3T8P+9cY+30AY+H8wdCqExBj71v3HGDLuqDYuAf76bQgIM61saVsURqTe+r1FzFq0la82HAkl45LjmTqyJ10jg0yuThpVVWZMEX/4EFz3Opx1ldkVnb6fX4VP7webnzGhW0z/pp33/TOQ8ahx+8IHYcSDWrfHXg1rPzD6gtQtm+AXAql3wHlTIKjD8eds/xbevQmqSiD6bLjpAwiNbd26XVVZCgVbjHmDCrYYW/lBSBoPyTd5djhvLk7nkZmp/UPccnZphRE5zro9RcxatIVFG/cDYLNaGJccz29H9qBLB4USt/TN4/Dt3yDuXOND3BM/iPO3wIsXGB1yRz8OQ6a4dv6Sf8BX043bF/weLnrYM1+HM1VTCavmGUOgC3cZ+wLCjddz8O3Qrv3Jz9+3Gt661lijKawz3LIAInu2eNkn5XRCSe6RsFG/bYXiPY2fF3UWjHoMeoxsvVpbW0Wx8dqU7Dv5V3vlkXNs/uAfbAQTvxDjtl/wUV9Djtw/0TEdehpfm5HCiDRqze5CZi3aytebjoSSq8+JZ+rFPencIdDk6qSBsgKjdaSmAiZ+Cl2Hm12Ra2qq4F8jjcnnul0ENy84vRWTl86GLx82bg//f8bIm7YSSKoPw8p/G6Gs7gM6qCMMuQcG3Wp8qDTVoZ3w5tVwMAvaRcBN70OngS1SdgMOuzH5YMHmI2Ejf7PxteokHeyDOhqX9SJ7QmQvI9Au+QdUFBnf75EGlzwG0f1a/meocyDLmLAvd63REmHzM776+B+5bTv6th/4+NXeP2azWI1wWB8wjgoZVaWt9zPVmbQQugxp1odUGJFTWpVTyKxFW1i8OR8AH6uFa87txD0X9yAhQqHEbXyaDj+/Aj1HGR8enuTLR2Dpc8YH3+SlZ3ZpIPOfxhwkAMPug7Q/eXcgqSw1Lm8tfd74wAIIiTPmoTl3Avid5v/RsgJ4+zrYu9LoY3Ld69BrdLOV3UBNFax6C75/FoqyT3yMxWosdhnZywgdHXsbtzv0gMCI448vP2j0J1r+stEPxmKFc24xWsyOXiCzOdUNl/7xBdiykOOWm2gp/qFG35+QGAiJrf0a1/B+cLTxGlSVGltlifHeqar7WtrI/dpjj75/0wfNHuwURqTJVmYfYtairXy35UgomTamL7ee39XkygQw/hJ7PgVwwuTM1v0r8ExsXwz/rp2C/9fzoM/lZ/6YP86FhbUdWYdONf4q9rZA4nQaH3rfPXmkP0B4Zzj/fqOvhI//mT9HZSm8P9GY6ddigyueg3NuPvPHrVNTCb+8ZfT5qVvM0jewNnD0go69jtyO6HZ6P9OBLGORxY0f1z5+kBHUht4Dfs102bm6AtZ9YPx75K07sr/naKMPl8UK9irjUom9uvZ2lRHC7FW1+yqP3K6pbLjfYTdaf+qDRqwR2ENijZDRzJdMzKAwIi5bsesQsxZt4futBQA8c30SV5/byeSqBID5txi/dJNuhKteMLuaUys/CC8Mg5K9kDIJxs5qvseuX9MGo8Pm6L96TyCpLIWP7oYNHxn3I7obl6UGXN/8nRPt1fDxVFj9jnF/5HQ4P/3MXsuaSuOS0g/PHrmkFBxjBKmUiS2zUGX2j/DFw7DnZ+N+SKwxHDzphtPv5FqSZ7RG/vQKlBu/D/ENhOQbIfUu8/vaeBCFETltj3+2kZe+246P1cLrkwZzfs9Is0uS3T8bfS+svnDvagiLN7uixjmd8N4EIzx16GkM422uv1Tr/PQK/C/duJ06GS6d6fmB5OB2Y8TL/g3Gv/OlM41hui05asTpNCaXW/IP4/7gO43ndfU5qyvglzcbhpCQWCOEnDux5ec2cTph/QKjpaSw9nJQdH+jk2v3i5r+OHtXwbK5xmglR+1U+qGdjJFK5044dSdhOY7CiJw2h8PJvfNX8cnqvQT7+/DenUPoF6fX3XSvjYFdS4zLE6P+YnY1jVv5b+Mvbqsv3LYI4pJb5nl+fg0+vc+4PfgOuOxJzw0kWxfBf/7P6JgZHAPj34SEwa33/Ef3x+k3Dq5+qWmXTqorjrSElOw19oXE1YaQCa0/wVp1BSx/Cb77O1TWdXK9xAglUX1PfI7Dbsx/8+MLxv+vOgmpcN5k6DMWbD4tX7uXUhiRM1JZY2fiq8v5cftBokP9WXD3MOLDW6CJVZpuyxcw73pjOF76evecuKpgG7w4HKrL4ZI/H1n0r6WseAM+uRdwGh182yeC1ce4lm/1qd1sR75abMfsr71ftz8gFLpf3Dz9MprC6TQ+yDP+bPwMnQbD9f82Zw6QtR/Ah3c1bXK06sPGa79kljH6AyA03ggh59xi/iyv5QeNIfE//cuYEt9iNcLRRQ8fWYKgosjo17Js7pHWFKuP0RckdTJ0SjGvfi+iMCJnrOhwNdfNXcqWvFJ6RAXzn7uGEhbofpPqtBkOhzGdev4mox9G2p+gXbjZVR1hr4ZXLoG9v0DXC+CWj05vGK+rfnkLPrqHZhvhEN7FeG3PuqplW1oqS+GjKcYsqmBczhjzVOsFoRPZvhjevbl2crT+cPMHR2ZyhdoQ8rqxiGGpsdwEoZ1geG0IMbP2EzmQZVyG2viJcd8vGIb+1ugY/MtbR4YVt2tv/J8adJt7XwL1QAoj0iz2Fh7m6n8uJbe4gsFdI/j3/w0mwFczH5pm9bvw4Z3Gbb9g4wPgvLuMFgGzLXoUfnjGmIhr8tLW/aW+c4kx9NJpN/4SdtiNrf7+UfscNccfV7cvb72xdg5A/EDjclgzz7sA1PYPudmYxt3qC2OeNPqHuIMTTY4WGg8rXjP6ltS9PmEJMDy9+Ub4tKRdS41OrntXNtwf2du4FDNg/OkPlZaTUhiRZrMpt5jrXsikpLKGywfE8vyvz8Fq9dBr857O6YQ1840Phf0bjH0WK/Qda0yC1Zr9DI628wd4/VeA07jM0O9Kc+o4U1VlkDnH+Mu/uszY1+dXkPYoRPZonufYtgg+uBUqCo3hm9f/Gzqf1zyP3VwO7oC3rjZCU7sI4/JF3VwnYZ2PCiF+5tbpCofD6OT64wsQ2AFS7zQuyXlqPyMPoTAizWrptgImvracaruTW8/vyiO/8pC5LryV0wlZXxsfnFkZR/Z3GmSEkj6/ar1Od4cPwQvnG/NJnHMLXDm7dZ63JZXkweKZsPINcDqMD+OB/wcXPgBBpzm6zOk0QmTGo8Zjxg+E8W+57xoxpfkw7zrjshsYc50M/50xZNaTQoiYSmFEmt1Hq/Zw77urAPjj5X25bXg3cwsSQ94G+HEOrHnPmFAJjA+O1Mlw7i2uTRfuKqcTPpgE6z80Jq+683uvmKip3v5NRp+DLQuN+/6hRifN8ya7NmdGVZnRP2T9h8b9cyfAmL+7/+WNylKjk2r7RONShhsuxCbuTWFEWsTcb7N44vNNWCww+4ZzuXyAm/5V1xaV7jcmBPvpX3D4oLHPP9SYbGrwnRCe0PzPuWoe/Hey0XJw65cQ76UjELZ/C1/+0VhjB4xOmyMfgf7Xn7qT7sEdMP9mYwZPq48xBHng/+nygLQJCiPSIpxOJ3/6eD1vZO7Cz2blzVsHk9rtBEuWi3mqDxsdXTPnHFli3mIzRocMmQLx557e4zrsxiWZsgIoP2AM6fzkXmNNi5HTjZlCvZnDAWvfN4bh1k1xHjPA6OTa7cITn5P1Nbw/yegfEhRl9A9piQ6xIm5KYURajN3h5O63V/DF+jxCA3z4YPJQekW34KUAOT0OB2z7CjJnGyNN6nQeaoSSnpccFS4KjoSMxu4fPmT0dThWl2Ew8ZOWnSnUnVQfNuam+P4ZqCw29vUcbcyrEtXHuO90GgsELvpTbf+QlNr+IXGmlS1ihhYNI3PmzOGpp54iNzeXpKQknn/+eQYPbrwXf2FhIQ8//DALFizg4MGDdOnShVmzZjFmzJhm/WGk9VRU27npX8tYsesQcWEBfDhlGNGhJk90JI3bt8ZoKVn3gTGM9UwEhBudOAMjjZVVRz7ScC6KtqKsAL590ljD5OiJtYbdB18/Buv+Yxx3zs0w5mnzJwITMUGLhZH58+czYcIE5s6dS2pqKrNmzeL9999n8+bNREVFHXd8VVUVw4YNIyoqioceeoj4+Hh27dpFeHg4SUlJzfrDSOs6VFbFNS8sZXtBGX1iQnj/riGEBKiDm1sr3mtMl/3zq8YMlBarMXSzLlwEdaj92sj9wAh1YjxWwTbI+NORibXqWH3g0ieMibTUP0TaqBYLI6mpqQwaNIjZs43hew6Hg4SEBKZOncqDDz543PFz587lqaeeYtOmTfj6nt4vMYUR95VzsJyr/rmUgtJKhvXowGu/GYyfTyvMuilnpqYKKkuMGVzbyuWVlrYr0+jkuudnY1n46/8NXYaaXZWIqZr6+e3Sp0ZVVRUrVqwgLS3tyANYraSlpZGZmXnCcz7++GOGDBnClClTiI6O5uyzz+bxxx/Hbrc3+jyVlZUUFxc32MQ9JUQE8tpvBhHoZ2PJtgM88J81eEA3JPHxM1o9FESaT5chxsKA//cF3L1MQUTEBS6FkYKCAux2O9HR0Q32R0dHk5ube8Jztm/fzgcffIDdbuezzz7jkUce4emnn+Yvf2l81dGZM2cSFhZWvyUktMCQRGk2/TuF8c+bzsVmtfDhL3t46ovNZpckYg6LxZhNNUgjzERc0eLt6Q6Hg6ioKF566SVSUlIYP348Dz/8MHPnzm30nGnTplFUVFS/5eTktHSZcoZG9I5i5tX9Afjn4ize/HGXyRWJiIincGm+6MjISGw2G3l5eQ325+XlERNz4t70sbGx+Pr6YrMdaQ7u27cvubm5VFVV4ed3/LTC/v7++Pu7+cyEcpzrByawr7CCZxdtYcZH64gO8WfUWW1wlIWIiLjEpZYRPz8/UlJSyMg4shaGw+EgIyODIUNOPJHPsGHD2LZtGw7HkfkJtmzZQmxs7AmDiHi2347swa8HJeBwwj3v/MLizfvNLklERNycy5dp0tPTefnll3njjTfYuHEjkydPpqysjEmTJgEwYcIEpk2bVn/85MmTOXjwIPfeey9btmzhf//7H48//jhTpkxpvp9C3IbFYuEv485mVL9oqmoc3PHvFWRszDv1iSIi0ma5vKzn+PHjyc/PZ/r06eTm5pKcnMzChQvrO7VmZ2djPWqthoSEBL744gvuv/9+BgwYQHx8PPfeey8PPPBA8/0U4lZ8bFZm33guv33nFxauz+Wut1Yw+8ZzGa1LNiIicgKaDl5aTLXdwX3zV/G/NfvwsVp47oZzGNNfC+uJiLQVLTLPiIgrfG1W/jE+mSuT46hxOJn6zi98snqv2WWJiIibURiRFuVjs/LM9clcfW48doeTe9/9hf/+ssfsskRExI0ojEiLs1ktPHVtEtcP7ITDCfe/t4oPVuw2uywREXETCiPSKmxWC09cPYAbUzvjdMLvP1jN/J+yzS5LRETcgMKItBqr1cJfx53NhCFdcDrhgf+s5e1lmqlVRKStUxiRVmWxWHj0irOYNCwRgIc/XMe/M3eaWpOIiJhLYURancViYfqv+nHHBd0AmP7Rel75YYfJVYmIiFkURsQUFouFaZf14e4R3QF47NMNvPhtlslViYiIGRRGxDQWi4Xfj+7Nby/uAcDMzzcx55ttJlclIiKtTWFETGWxWEgf1Zv703oB8NQXm/nHoq0mVyUiIq1JYUTcwr1pPfn96N4APLtoC898uRkPWKlARESagcKIuI0pF/XgoTF9AHju6208+YUCiYhIW6AwIm7ljgu688iv+gHwwuIsHv9sowKJiIiXUxgRt3Pr+V159IqzAHj5+x18tSHP5IpERKQlKYyIW5o4NJGJQ7oA8Pm6XJOrERGRlqQwIm5rTP9YAL7ZvB+7Q5dqRES8lcKIuK2ULu0Ja+dLYXk1K7MPmV2OiIi0EIURcVs+NisjencEIGPjfpOrERGRlqIwIm5tZN9oADI2qhOriIi3UhgRt3Zhz47YrBa27i8l+0C52eWIiEgLUBgRtxYW6MugxPYAZGxS64iIiDdSGBG3l1Z/qUb9RkREvJHCiLi9i/tEAbBsxwFKKqpNrkZERJqbwoi4vW4dg+kWGUS13cn3WwvMLkdERJqZwoh4hJF9jdaRRRpVIyLidRRGxCNc3MfoN7J4c75mYxUR8TIKI+IRBia2JzTAh4NlVazK0WysIiLeRGFEPIKvzcqFvY1LNRpVIyLiXRRGxGOk9VUYERHxRgoj4jEu7GXMxro5r4Scg5qNVUTEWyiMiMcID/QjpYsxG+vXm9Q6IiLiLRRGxKOkaYiviIjXURgRj1I3xHfZ9oOUVtaYXI2IiDQHhRHxKN07BpHYIZAqu4MftuabXY6IiDQDhRHxKBaLhZG1C+ct0qgaERGvoDAiHmdk7cJ532zaj0OzsYqIeLzTCiNz5swhMTGRgIAAUlNTWb58eaPHvv7661gslgZbQEDAaRcsMqhrBCH+Phwoq2LV7kKzyxERkTPkchiZP38+6enpzJgxg5UrV5KUlMTo0aPZv7/xJvPQ0FD27dtXv+3ateuMipa2zddm5YLeHQH4WpdqREQ8nsth5JlnnuH2229n0qRJ9OvXj7lz5xIYGMirr77a6DkWi4WYmJj6LTo6+oyKFtEQXxER7+FSGKmqqmLFihWkpaUdeQCrlbS0NDIzMxs9r7S0lC5dupCQkMCVV17J+vXrT/o8lZWVFBcXN9hEjjaiVxRWC2zKLWH3Ic3GKiLiyVwKIwUFBdjt9uNaNqKjo8nNzT3hOb179+bVV1/lo48+4q233sLhcDB06FB2797d6PPMnDmTsLCw+i0hIcGVMqUNaB90ZDbWbzQbq4iIR2vx0TRDhgxhwoQJJCcnc+GFF7JgwQI6duzIiy++2Og506ZNo6ioqH7Lyclp6TLFA2mIr4iId3ApjERGRmKz2cjLa3idPi8vj5iYmCY9hq+vL+eccw7btm1r9Bh/f39CQ0MbbCLHqhvim5l1gDLNxioi4rFcCiN+fn6kpKSQkZFRv8/hcJCRkcGQIUOa9Bh2u521a9cSGxvrWqUix+gRFUzniNrZWLcVmF2OiIicJpcv06Snp/Pyyy/zxhtvsHHjRiZPnkxZWRmTJk0CYMKECUybNq3++D//+c98+eWXbN++nZUrV3LzzTeza9cubrvttub7KaRNMmZjNVpHMjSqRkTEY/m4esL48ePJz89n+vTp5ObmkpyczMKFC+s7tWZnZ2O1Hsk4hw4d4vbbbyc3N5f27duTkpLC0qVL6devX/P9FNJmjewTzWtLdvL1pnwcDidWq8XskkRExEUWp9Pp9vNpFxcXExYWRlFRkfqPSANVNQ5SHvuKksoa/jtlGMkJ4WaXJCIitZr6+a21acSj+flYuaBX3WysulQjIuKJFEbE413cp242Vg3xFRHxRAoj4vEu6hOFxQIb9hWzt/Cw2eWIiIiLFEbE40UE+XFuZ2M21q81G6uIiMdRGBGvoCG+IiKeS2FEvEJa7dTwS7IOUF6l2VhFRDyJwoh4hZ5RwXRq346qGgdLth0wuxwREXGBwoh4BYvFUt86oks1IiKeRWFEvEbdEN+vN+3H4XD7ufxERKSWwoh4jdRuEQT52dhfUsm6vUVmlyMiIk2kMCJew9/HVj8ba4YmQBMR8RgKI+JV6i7VZGxSvxEREU+hMCJepW421nV7isktqjC7HBERaQKFEfEqkcH+9Sv3ajZWERHPoDAiXkdDfEVEPIvCiHiduqnhf9hWwOEqu8nViIjIqSiMiNfpHR1CfHg7KmscLM0qMLscERE5BYUR8ToWi6W+dWSRhviKiLg9hRHxSkdmY83D6dRsrCIi7kxhRLzSed06EOhnI6+4kvV7i80uR0RETkJhRLxSgK+N4T0jAc3GKiLi7hRGxGuN7FM7xFezsYqIuDWFEfFaF9X2G1mzu4i8Ys3GKiLirhRGxGt1DPEnqXY21m80G6uIiNtSGBGvllbbOvLlBl2qERFxVwoj4tUu6x8DwHdb8jlUVmVyNSIiciIKI+LVekSF0C82lBqHk8/X5ZpdjoiInIDCiHi9K5PjAPh49R6TKxERkRNRGBGv96skI4ws23GQfUWHTa5GRESOpTAiXi8+vB2DEyNwOuHT1fvMLkdERI6hMCJtwhW1l2o+0qUaERG3ozAibcKY/rH4WC2s21NMVn6p2eWIiMhRFEakTYgI8qtfq+bjVXtNrkZERI6mMCJtxpXJ8QB8vHovTqfT5GpERKSOwoi0GZf0iybA18qOgjLW7Sk2uxwREamlMCJtRpC/D2l9jZV8P1qljqwiIu7itMLInDlzSExMJCAggNTUVJYvX96k8959910sFgvjxo07nacVOWN1l2o+WbMXu0OXakRE3IHLYWT+/Pmkp6czY8YMVq5cSVJSEqNHj2b//pOvirpz505+97vfMXz48NMuVuRMXdirI2HtfMkrrmTZjgNmlyMiIpxGGHnmmWe4/fbbmTRpEv369WPu3LkEBgby6quvNnqO3W7npptu4tFHH6Vbt25nVLDImfDzsXLZ2cbieZ+s1qgaERF34FIYqaqqYsWKFaSlpR15AKuVtLQ0MjMzGz3vz3/+M1FRUdx6661Nep7KykqKi4sbbCLNpW4CtM/W5lJZYze5GhERcSmMFBQUYLfbiY6ObrA/Ojqa3NwTr4j6ww8/8Morr/Dyyy83+XlmzpxJWFhY/ZaQkOBKmSInldq1A9Gh/hQdrua7LQVmlyMi0ua16GiakpISbrnlFl5++WUiIyObfN60adMoKiqq33JyclqwSmlrbFYLYwfUTg+vUTUiIqbzceXgyMhIbDYbeXl5Dfbn5eURExNz3PFZWVns3LmTsWPH1u9zOBzGE/v4sHnzZrp3737cef7+/vj7+7tSmohLrkiO418/7GDRxjzKKmsI8nfpv4KIiDQjl1pG/Pz8SElJISMjo36fw+EgIyODIUOGHHd8nz59WLt2LatWrarfrrjiCi666CJWrVqlyy9imv7xYXSNDKKi2sFXG/JOfYKIiLQYl/8cTE9PZ+LEiQwcOJDBgwcza9YsysrKmDRpEgATJkwgPj6emTNnEhAQwNlnn93g/PDwcIDj9ou0JovFwhVJcfwjYysfrdrDuHPizS5JRKTNcjmMjB8/nvz8fKZPn05ubi7JycksXLiwvlNrdnY2VqsmdhX3d0WyEUa+31rAwbIqIoL8zC5JRKRNsjg9YMWw4uJiwsLCKCoqIjQ01OxyxIv86vnvWbenmL+MO5ubz+tidjkiIl6lqZ/fasKQNu3KpNqVfFdpAjQREbMojEib9qukWCwWWL7zIHsKD5tdjohIm6QwIm1abFg7BidGAJoeXkTELAoj0ubVreSrSzUiIuZQGJE277KzY/C1Wdiwr5iteSVmlyMi0uYojEib1z7Ijwt6dgTgY12qERFpdQojIhxZyffj1XvxgNHuIiJeRWFEBLikXzTtfG3sOlDO6t1FZpcjItKmKIyIAIF+Pow6y5hFWCv5ioi0LoURkVpXJBmXaj5dsw+7Q5dqRERai8KISK3hPTsSHuhLfkklP24/YHY5IiJthsKISC0/Hytj+scCulQjItKaFEZEjlJ3qebzdblUVNtNrkZEpG1QGBE5yuDECGJCAyipqGHx5nyzyxERaRMURkSOYrVa6ucc0Vo1IiKtQ2FE5Bh1l2oWbcyjpKLa5GpERLyfwojIMc6KC6VbxyAqaxx8uT7P7HJERLyewojIMSwWC1cmGSv5fqRLNSIiLU5hROQE6vqNLNlWQEFppcnViIh4N4URkRPoGhnEgE5h2B1OPlu7z+xyRES8msKISCPqOrJ+tEqXakREWpLCiEgjxibFYbHAil2HyDlYbnY5IiJeS2FEpBHRoQEM6dYBgE/WqHVERKSlKIyInETdpZqPdalGRKTFKIyInMRlZ8fia7OwKbeEzbklZpcjIuKVFEZETiIs0JcRvaMA+Hi1VvIVEWkJCiMip3D0qBq7w2lyNSIi3kdhROQU0vpGExrgw+5Dh/nwF7WOiIg0N4URkVNo52fj7ot6APD0l5upqLabXJGIiHdRGBFpgt8MTSQ+vB37iip45YcdZpcjIuJVFEZEmiDA18bvRvcC4IXFWRzQejUiIs1GYUSkia5MiuesuFBKK2t4/uttZpcjIuI1FEZEmshqtfDQmL4AvPXjLnYUlJlckYiId1AYEXHBsB6RjOjdkRqHkycXbjK7HBERr6AwIuKiaZf1xWqBz9flsmLXQbPLERHxeAojIi7qHRPCdSkJAPz1fxtxOjURmojImTitMDJnzhwSExMJCAggNTWV5cuXN3rsggULGDhwIOHh4QQFBZGcnMybb7552gWLuIP0Ub0I8LWyMruQhetyzS5HRMSjuRxG5s+fT3p6OjNmzGDlypUkJSUxevRo9u/ff8LjIyIiePjhh8nMzGTNmjVMmjSJSZMm8cUXX5xx8SJmiQ4N4Pbh3QD428JNVNsdJlckIuK5LE4X25hTU1MZNGgQs2fPBsDhcJCQkMDUqVN58MEHm/QY5557LpdffjmPPfZYk44vLi4mLCyMoqIiQkNDXSlXpMWUVtYw4qlvKCit4tErzmLi0ESzSxIRcStN/fx2qWWkqqqKFStWkJaWduQBrFbS0tLIzMw85flOp5OMjAw2b97MBRdc0OhxlZWVFBcXN9hE3E2wvw/3phkTof0jYyvFFdUmVyQi4plcCiMFBQXY7Xaio6Mb7I+OjiY3t/Hr5kVFRQQHB+Pn58fll1/O888/zyWXXNLo8TNnziQsLKx+S0hIcKVMkVbz60EJdOsYxMGyKuYuzjK7HBERj9Qqo2lCQkJYtWoVP/30E3/9619JT09n8eLFjR4/bdo0ioqK6recnJzWKFPEZb42Kw9e2geAV37Ywd7CwyZXJCLieXxcOTgyMhKbzUZeXl6D/Xl5ecTExDR6ntVqpUcPY9XT5ORkNm7cyMyZMxkxYsQJj/f398ff39+V0kRMc0m/aAYnRrB850Ge/nILT1+fZHZJIiIexaWWET8/P1JSUsjIyKjf53A4yMjIYMiQIU1+HIfDQWWlFhoT72CxWJg2xmgdWfDLbjbsVR8nERFXuHyZJj09nZdffpk33niDjRs3MnnyZMrKypg0aRIAEyZMYNq0afXHz5w5k6+++ort27ezceNGnn76ad58801uvvnm5vspREx2Tuf2XD4gFqcTZn6+0exyREQ8ikuXaQDGjx9Pfn4+06dPJzc3l+TkZBYuXFjfqTU7Oxur9UjGKSsr4+6772b37t20a9eOPn368NZbbzF+/Pjm+ylE3MADo/vw5fpcvt9awHdb8rmgV0ezSxIR8QguzzNiBs0zIp7iz59s4NUlO+gTE8L/fjscm9VidkkiIqZpkXlGROTkpl7cg5AAHzbllrBg5W6zyxER8QgKIyLNqH2QH/dcZIwce/rLLRyusptckYiI+1MYEWlmE4cmEh/ejtziCl5dssPsckRE3J7CiEgzC/C18bvRxjTxLyzO4kCphrGLiJyMwohIC7gyKZ6z40MprazhuYytZpcjIuLWFEZEWoDVauGhy/oC8PaybLbnl5pckYiI+1IYEWkhQ3tEclHvjtQ4nDy5cLPZ5YiIuC2FEZEW9OBlfbFaYOH6XH7eedDsckRE3JLCiEgL6h0TwnUpCQA8/tlGPGCOQRGRVqcwItLC0kf1op2vjZXZhSxcl2t2OSIibkdhRKSFRYcGcPvwrgD8beEmqmocJlckIuJeFEZEWsEdF3YnMtiPnQfKmf21hvqKiBxNYUSkFQT7+/DIr/oB8Pw321i8eb/JFYmIuA+FEZFWcmVyPDemdsbphPvnr2JP4WGzSxIRcQsKIyKtaPqv+nF2fCiHyquZ8vZK9R8REUFhRKRVBfjaeOGmFEIDfFiVU8jjn200uyQREdMpjIi0soSIQJ6+PhmA15fu5NM1e80tSETEZAojIia4pF80d13YHYAHPlhDltauEZE2TGFExCS/G9WLwV0jKKuyM/mtFZRX1ZhdkoiIKRRGREziY7My+4ZziAz2Z0teKX/8cJ2mixeRNklhRMREUaEBPH/DOVgtsOCXPbz7U47ZJYmItDqFERGTDenegd+N7g3AjI/Xs25PkckViYi0LoURETdw1wXdSesbRVWNg8lvr6CovNrskkREWo3CiIgbsFotPH1dMp3atyPn4GH+3/ur1X9ERNoMhRERNxEW6MsLN6XgZ7OyaGMeL3233eySRERahcKIiBvp3ymMGVcYC+o9+cVmlm0/YHJFIiItT2FExM3cOLgzV50Tj93h5J53fmF/SYXZJYmItCiFERE3Y7FY+OtVZ9MrOpj8kkrufWcVNXYtqCci3kthRMQNBfr58M+bUgj0s5G5/QDPLtpidkkiIi1GYUTETfWICuaJawYAMOebLL7elGdyRSIiLUNhRMSNXZEUx8QhXQC4f/5qcg6Wm1yRiEjzUxgRcXMPXd6XpIRwig5XM2XeSipr7GaXJCLSrBRGRNycv4+NOTeeQ3igL2t2F/GXTzeaXZKISLNSGBHxAJ3aB/Ls+GQA3vxxF/9ZsdvcgkREmpHCiIiHuKh3FFMv7gHA7z9YzUer9phckYhI81AYEfEg96X14rqUTjiccN/8Vbz3c47ZJYmInLHTCiNz5swhMTGRgIAAUlNTWb58eaPHvvzyywwfPpz27dvTvn170tLSTnq8iDTOZrXwt2sGcGNqZ5xO+MMHa3h72S6zyxIROSMuh5H58+eTnp7OjBkzWLlyJUlJSYwePZr9+/ef8PjFixdzww038M0335CZmUlCQgKjRo1izx41MYucDqvVwl/Hnc1vhiYC8PCH63htyQ5zixIROQMWp4vrlKempjJo0CBmz54NgMPhICEhgalTp/Lggw+e8ny73U779u2ZPXs2EyZMaNJzFhcXExYWRlFREaGhoa6UK+K1nE4nT3y+iRdrV/eddlkf7rywu8lViYgc0dTPb5daRqqqqlixYgVpaWlHHsBqJS0tjczMzCY9Rnl5OdXV1URERDR6TGVlJcXFxQ02EWnIYrHw4GV9+G1tp9aZn2/i+YytJlclIuI6l8JIQUEBdrud6OjoBvujo6PJzc1t0mM88MADxMXFNQg0x5o5cyZhYWH1W0JCgitlirQZFouF9FG9+X+X9ALg6a+28PSXm3GxwVNExFStOprmiSee4N133+XDDz8kICCg0eOmTZtGUVFR/ZaToxEDIiczdWRPHhrTB4Dnv97GE59vUiAREY/h48rBkZGR2Gw28vIaLtiVl5dHTEzMSc/9+9//zhNPPMGiRYsYMGDASY/19/fH39/fldJE2rw7LuiOn83Knz7ZwIvfbaeyxsGMsf2wWCxmlyYiclIutYz4+fmRkpJCRkZG/T6Hw0FGRgZDhgxp9Lwnn3ySxx57jIULFzJw4MDTr1ZETuo3w7ry+FX9AXh96U4e/u86HA61kIiIe3OpZQQgPT2diRMnMnDgQAYPHsysWbMoKytj0qRJAEyYMIH4+HhmzpwJwN/+9jemT5/OvHnzSExMrO9bEhwcTHBwcDP+KCICcGNqZ3xsFh74zxrmLcumusbBE9cMwGZVC4mIuCeXw8j48ePJz89n+vTp5ObmkpyczMKFC+s7tWZnZ2O1HmlweeGFF6iqquLaa69t8DgzZszgT3/605lVLyIndP3ABPx9rKS/t5r3V+ymyu7g6euS8LFp0mURcT8uzzNiBs0zInJ6Plu7j9++8ws1Didj+sfwj1+fg68CiYi0khaZZ0REPMuY/rG8cHMKfjYrn63NZfJbK6mssZtdlohIAwojIl7ukn7RvDQhBT8fK4s25nHnmyuoqFYgERH3oTAi0gaM6B3Fa78ZRICvlcWb87ntjZ8pr6oxuywREUBhRKTNGNYjkjcmDSbIz8YP2wq44eVlLN9x0OyyREQURkTaktRuHfj3ramE+PuwOqeQ61/MZPyLmSzZVqAZW0XENBpNI9IG7T5Uzj8XZ/H+zzlU241fAed2DmfqyJ6M6NVRs7aKSLNo6ue3wohIG7a38DAvfpvFOz/lUFXjAGBApzDuuagHl/SLVigRkTOiMCIiTba/uIKXv9/OWz9mc7h2pE2fmBCmXtyTy86OwarZW0XkNCiMiIjLDpRW8soPO/h35i5KK43RNj2igrnnoh78akCsZnAVEZcojIjIaSssr+K1JTt5dckOSiqMUJLYIZC7L+rBVefEaxZXEWkShREROWPFFdX8e+lOXvlhB4fKqwHo1L4dk0d059qUTvj72EyuUETcmcKIiDSbssoa3l62i5e+20FBaSUAsWEB3Da8Gxf26ki3yCD1KxGR4yiMiEizq6i2887ybOZ+m0VecWX9/hB/H86OD2NAQhhJncIZ0CmM+PB2Go0j0sYpjIhIi6mssfP+z7v57y97WLe3iIpqx3HHdAjyY0CnMAZ0CicpwfgaGexvQrUiYhaFERFpFTV2B1v3l7JmdyGrdxexZnchm/aVUOM4/ldLfHi7+mAyoFMY/ePDCAnwNaFqEWkNCiMiYpqKajsb9xWzZncRq3cXsjqnkO0FZRz728ZigW6RQQzrEcmofjGkdovQSB0RL6IwIiJupaSimrV7ilhT23qyOqeIPYWHGxwTEuDDxX2iGNUvhgt7dyTY38ekakWkOSiMiIjbKyit5JfsQjI25rFoYx4FpVX13/OzWRnWowOX9IshrV8UUSEBJlYqIqdDYUREPIrd4WRVziG+XJ/Hlxvy2FFQVv89iwXOSQhn1FkxjOoXTbeOwSZWKiJNpTAiIh7L6XSSlV/KF7XBZHVOYYPv94gK5pJ+0YzqF01Sp3DNcSLiphRGRMRr5BZV8NXGPL7akEdmVgHV9iO/tqJC/LmkXzRjk+I4r1sHE6sUkWMpjIiIVyquqGbx5ny+XJ/L4s359Qv6AYzo3ZGHx/SlZ3SIiRWKSB2FERHxepU1dn7cfpDP1uxjwS+7qbY7sVkt3Di4M/el9aSDJlkTMZXCiIi0KTsKynji8418sT4PMIYJT724BxOHJmpBPxGTKIyISJuUmXWAv/xvA+v3FgOQENGOaZf15bKzY7RWjkgrUxgRkTbL7nCyYOVunvpiM/tLjAX9BiW255Ff9WNAp3BzixNpQxRGRKTNK6us4cXvtvPSd1n1i/ldfU48v7+0N7Fh7Uyu7sTKKmv4bO0+quwOrkiK09o94tEURkREau0tPMzfv9jMgl/2ABDga+WOC7pz5wXdCHKTKec37itm3rJsPvxlT/0IodAAHyYN68qkYYmEB/qZXKGI6xRGRESOsWZ3IY99uoGfdh4CjDlKfj+6N9ec28mUidMqqu18tnYfby/LZsWuQ/X7EzsEYrVa2J5vzEIb5Gfj5iFduO38bnQM0Qgh8RwKIyIiJ+B0Olm4LpfHP99IzkFjob6z4kL54+X9GNK9dSZNy8ovZd6ybD5YsZuiw9UA+FgtjDormptSuzCkWwecwMJ1uTz/9VY25ZYA4O9j5YbBnbnzwm5ue5lJ5GgKIyIiJ1FZY+eNpTt5PmMbJbWXRdL6RjGidxR9Y0PoFR3SrP01qmocfLE+l3nLssncfqB+f3x4O25M7cx1AzudcDFAp9NJxsb9PP/Ntvpp8X1tFq5NSWDyhd3p3CGw2WoUaW4KIyIiTXCgtJJnF21h3rJsHMf8NowPb0efmBD6xIbQOyaUPjEhdI0MwtdmbfLj5xwsZ97ybN7/Oad+VWKrBS7uE8VNqV24oFdHbE24ROR0Olmy7QDPf72VZTsOAmCzWrgyOY67R/SgR5QWDxT3ozAiIuKCrXklfLByN5v2lbA5t4Tc4ooTHudns9KtYxB9Y0PpHRNC75gQ+sSEEBMaUD+PSY3dwdeb9vP2smy+25pP3W/ZqBB/fj24M78elEBc+OlfZlm+4yCzv9nGd1vyAWNV4zH9Y5kyogf94vQ7UtyHwoiIyBkoLK9ic24Jm/NK2LivhM25xWzJK22wFs7Rwtr50jsmhC4RgXy/taBBmBneM5KbUrswsm+US60qp7I6p5DZ32zjqw159fvS+kZxz8U9SU4Ib7bnETldCiMiIs3M6XSy+9BhNueWsCm3mE25RivK9oIy7Mdc4+kQ5Md1AxO4YXACXToEtWhdm3KLmfNNFp+u2VvfCjO8ZyR3j+jB4K4RTboMJNISFEZERFpJZY2drP1lbMotZnt+Gb1iQhh9VnSrr4mTlV/KC4uz+PCXPfXhKNDPRr/YUPp3CqN/fBgDOoXRNTJYAUVaRYuGkTlz5vDUU0+Rm5tLUlISzz//PIMHDz7hsevXr2f69OmsWLGCXbt28eyzz3Lfffe59HwKIyIiTZdzsJwXvs3io1/2UFZlP+77QX42zooLqw8o/TuF0bVDkClzrYh3a+rnt8tTD86fP5/09HTmzp1Lamoqs2bNYvTo0WzevJmoqKjjji8vL6dbt25cd9113H///a4+nYiIuCghIpDHr+rPY1eezY6CUtbsLmLtniLW7i5i/d5iyqrsLN95kOU7D9afE+zvw1lxofXhpH98GIkKKNJKXG4ZSU1NZdCgQcyePRsAh8NBQkICU6dO5cEHHzzpuYmJidx3331qGRERMYnd4SQr3wgo6/YUsWZ3IRv2Fdev3XO0EH8fzooPZVj3SMYMiKV7Rw0fFte0SMtIVVUVK1asYNq0afX7rFYraWlpZGZmnn61IiLSKmxWC72ijUndrk3pBBhDkbfll7K2tgVlze4iNu4rpqSyhh+3H+TH7Qd5+qst9I4OYUz/WC4fEEOPqBCTfxLxJi6FkYKCAux2O9HR0Q32R0dHs2nTpmYrqrKyksrKyvr7xcXFzfbYIiLSkI/NSp+YUPrEhHLdwAQAqu0OtuaV8kvOIb5cn8eSbQVszjOGOj+7aAu9ooONYNI/lp7RCiZyZtxjucpjzJw5k0cffdTsMkRE2ixfm5V+caH0iwvlptQuFJZX8eWGPD5bu48l2wrYklfKlrytzFq0lZ5RtcFkQCy9WjCY2B1OjQLyUi6FkcjISGw2G3l5eQ325+XlERMT02xFTZs2jfT09Pr7xcXFJCQkNNvji4iIa8ID/bh+YALXD0ygqLyarzYaweT7rfls3V/KPzK28o+MrfSIOtJi0is6uH5W2lNxOp0Ullezp/Awuw+Vs/vQ4drbh9lzyNhXUllDv9hQhvWIZGj3DgzuGkGgn1v+TS0uculf0c/Pj5SUFDIyMhg3bhxgdGDNyMjgnnvuabai/P398ffXMtkiIu4oLNCXa1M6cW1KJ4oOV7NoQ10wKWDb/lKey9jKcxlb6d4xiMv7xzJmQCy9o0PIL62sDRZG0KgLGXWho/wEw5CPtX5vMev3FvPSd9vxtVk4J6E9Q3t0YFiPSJITwpt1hltpPS6Pppk/fz4TJ07kxRdfZPDgwcyaNYv33nuPTZs2ER0dzYQJE4iPj2fmzJmA0el1w4YNAIwZM4abbrqJm266ieDgYHr06NGk59RoGhER91dccSSYfLelgCr7kRE6vjYL1fZTf9x0DPEnPrwdndq3I759OzqFt6NT+0Di27cjyN+Hn3ceZMm2ApZsO8CewsMNzg30szG4awTDukcytEcH+saEamiyyVp00rPZs2fXT3qWnJzMc889R2pqKgAjRowgMTGR119/HYCdO3fStWvX4x7jwgsvZPHixc36w4iIiHsorqjm6437+d/afXy7JZ+qGgcWC8SEBhhBI7w2bLQPrA8fceHtCPBt2qy1TqeT7IPlLNl2gCVZBWRmHeBgWVWDYyKC/BjSvQPDukcyrEcHOkcENvmykTQPTQcvIiJuobSyhkNlVUSHBuDn0zKXURwOJ5tyS1iaVcCSbQUs23HwuMs+8eHtGNajA/07hdO1QxCJkYHEhbVT60kLUhgREZE2q6rGwerdhSzZVsDSbQf4JefQCS8T+flY6RIRSGJkEF0jg+jSIbA2qAQRExqgoHKGFEZERERqlVfVsHzHQTK3H2BbXik7DpSRc7D8pP1YAnytdIkwWlASI4PqQ0pihyCiQ/11yacJFEZEREROosbuYG9hBTsOlLGzoIwdBWXsPFDGrgPl5Bwsp8bR+MdjoJ+Nbh2D6N4xmG6RwXSPMm53jQxqcr+XtkBhRERE5DRV2x3sOXS4PqjsLChjx4FydhaUsftQOY3lFIvF6JvSvWOwEVRqA0v3qCA6Bre91hSFERERkRZQVeMg+2A52/NLycovIyu/lO35pWzbX0pxRU2j54X4+9AtKpjutQGlc0Rg/eNV2R1U1TiorLEb92scVNodVFYf+V6D7x+1z9/XRng7X9oH+hEe6EtYoC/h7Yzb4e18Ca/dHx7oSztfW6sGIoURERGRVuR0OjlQVkXW/lK2F5SRtb/UCCoFRv+Uk1z1aTV+NmttWDHCS1h9YPHl5vO60KVDULM+X4us2isiIiInZrFYiAz2JzLYn9RuHRp8r6Lazq4Dda0pRovK7kPlWC0W/Hys+PvY8Pex4udjxc9mxd/X+Ornc2Tz97EZX21196342qxU1NgpLK+m6HA1h8qqKDxcXXu/isLy6tr7VVTbnVTZHeSXVJJfUnlc/Zf1j232MNJUCiMiIiItLMDXRu+YEHrHmLPCsdPppLzKXh9MimpDyqHyqvog06l9O1NqA4URERERr2exWAjy9yHI34f4cPNCR2O0opCIiIiYSmFERERETKUwIiIiIqZSGBERERFTKYyIiIiIqRRGRERExFQKIyIiImIqhRERERExlcKIiIiImEphREREREylMCIiIiKmUhgRERERUymMiIiIiKk8YtVep9MJQHFxscmViIiISFPVfW7XfY43xiPCSElJCQAJCQkmVyIiIiKuKikpISwsrNHvW5yniituwOFwsHfvXkJCQrBYLM32uMXFxSQkJJCTk0NoaGizPa7otW1Jem1bhl7XlqPXtuW4+2vrdDopKSkhLi4Oq7XxniEe0TJitVrp1KlTiz1+aGioW/4jegO9ti1Hr23L0OvacvTathx3fm1P1iJSRx1YRURExFQKIyIiImKqNh1G/P39mTFjBv7+/maX4nX02rYcvbYtQ69ry9Fr23K85bX1iA6sIiIi4r3adMuIiIiImE9hREREREylMCIiIiKmUhgRERERU7XpMDJnzhwSExMJCAggNTWV5cuXm12Sx/vTn/6ExWJpsPXp08fssjzOd999x9ixY4mLi8NisfDf//63wfedTifTp08nNjaWdu3akZaWxtatW80p1sOc6rX9zW9+c9x7+NJLLzWnWA8yc+ZMBg0aREhICFFRUYwbN47Nmzc3OKaiooIpU6bQoUMHgoODueaaa8jLyzOpYs/RlNd2xIgRx71v77rrLpMqdl2bDSPz588nPT2dGTNmsHLlSpKSkhg9ejT79+83uzSPd9ZZZ7Fv37767YcffjC7JI9TVlZGUlISc+bMOeH3n3zySZ577jnmzp3LsmXLCAoKYvTo0VRUVLRypZ7nVK8twKWXXtrgPfzOO++0YoWe6dtvv2XKlCn8+OOPfPXVV1RXVzNq1CjKysrqj7n//vv55JNPeP/99/n222/Zu3cvV199tYlVe4amvLYAt99+e4P37ZNPPmlSxafB2UYNHjzYOWXKlPr7drvdGRcX55w5c6aJVXm+GTNmOJOSkswuw6sAzg8//LD+vsPhcMbExDifeuqp+n2FhYVOf39/5zvvvGNChZ7r2NfW6XQ6J06c6LzyyitNqceb7N+/3wk4v/32W6fTabxHfX19ne+//379MRs3bnQCzszMTLPK9EjHvrZOp9N54YUXOu+9917zijpDbbJlpKqqihUrVpCWlla/z2q1kpaWRmZmpomVeYetW7cSFxdHt27duOmmm8jOzja7JK+yY8cOcnNzG7x/w8LCSE1N1fu3mSxevJioqCh69+7N5MmTOXDggNkleZyioiIAIiIiAFixYgXV1dUN3rd9+vShc+fOet+66NjXts7bb79NZGQkZ599NtOmTaO8vNyM8k6LRyyU19wKCgqw2+1ER0c32B8dHc2mTZtMqso7pKam8vrrr9O7d2/27dvHo48+yvDhw1m3bh0hISFml+cVcnNzAU74/q37npy+Sy+9lKuvvpquXbuSlZXFQw89xGWXXUZmZiY2m83s8jyCw+HgvvvuY9iwYZx99tmA8b718/MjPDy8wbF637rmRK8twI033kiXLl2Ii4tjzZo1PPDAA2zevJkFCxaYWG3TtckwIi3nsssuq789YMAAUlNT6dKlC++99x633nqriZWJNM2vf/3r+tv9+/dnwIABdO/encWLFzNy5EgTK/McU6ZMYd26deov1gIae23vuOOO+tv9+/cnNjaWkSNHkpWVRffu3Vu7TJe1ycs0kZGR2Gy243px5+XlERMTY1JV3ik8PJxevXqxbds2s0vxGnXvUb1/W0e3bt2IjIzUe7iJ7rnnHj799FO++eYbOnXqVL8/JiaGqqoqCgsLGxyv923TNfbankhqaiqAx7xv22QY8fPzIyUlhYyMjPp9DoeDjIwMhgwZYmJl3qe0tJSsrCxiY2PNLsVrdO3alZiYmAbv3+LiYpYtW6b3bwvYvXs3Bw4c0Hv4FJxOJ/fccw8ffvghX3/9NV27dm3w/ZSUFHx9fRu8bzdv3kx2drbet6dwqtf2RFatWgXgMe/bNnuZJj09nYkTJzJw4EAGDx7MrFmzKCsrY9KkSWaX5tF+97vfMXbsWLp06cLevXuZMWMGNpuNG264wezSPEppaWmDv2h27NjBqlWriIiIoHPnztx333385S9/oWfPnnTt2pVHHnmEuLg4xo0bZ17RHuJkr21ERASPPvoo11xzDTExMWRlZfGHP/yBHj16MHr0aBOrdn9Tpkxh3rx5fPTRR4SEhNT3AwkLC6Ndu3aEhYVx6623kp6eTkREBKGhoUydOpUhQ4Zw3nnnmVy9ezvVa5uVlcW8efMYM2YMHTp0YM2aNdx///1ccMEFDBgwwOTqm8js4Txmev75552dO3d2+vn5OQcPHuz88ccfzS7J440fP94ZGxvr9PPzc8bHxzvHjx/v3LZtm9lleZxvvvnGCRy3TZw40el0GsN7H3nkEWd0dLTT39/fOXLkSOfmzZvNLdpDnOy1LS8vd44aNcrZsWNHp6+vr7NLly7O22+/3Zmbm2t22W7vRK8p4Hzttdfqjzl8+LDz7rvvdrZv394ZGBjovOqqq5z79u0zr2gPcarXNjs723nBBRc4IyIinP7+/s4ePXo4f//73zuLiorMLdwFFqfT6WzN8CMiIiJytDbZZ0RERETch8KIiIiImEphREREREylMCIiIiKmUhgRERERUymMiIiIiKkURkRERMRUCiMiIiJiKoURERERMZXCiIiIiJhKYURERERMpTAiIiIipvr/uDHeI5exwlIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f51944e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Testing on Test Set\n",
      "======================================================================\n",
      "Loaded best model from epoch 27\n",
      "  Train Acc: 100.00%\n",
      "  Val Acc:   73.97%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.18it/s, loss=0.5635, acc=69.86%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Test Results\n",
      "======================================================================\n",
      "Test Loss:     0.5649\n",
      "Test Accuracy: 69.86%\n",
      "Correct:       51/73\n",
      "======================================================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.71      0.68      0.69        37\n",
      "     Class 1       0.68      0.72      0.70        36\n",
      "\n",
      "    accuracy                           0.70        73\n",
      "   macro avg       0.70      0.70      0.70        73\n",
      "weighted avg       0.70      0.70      0.70        73\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[25 12]\n",
      " [10 26]]\n",
      "\n",
      "True Negatives:  25\n",
      "False Positives: 12\n",
      "False Negatives: 10\n",
      "True Positives:  26\n",
      "\n",
      "Per-Class Accuracy:\n",
      "  Class 0: 67.57%\n",
      "  Class 1: 72.22%\n",
      "\n",
      "======================================================================\n",
      "Testing Complete!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a990638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98584fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
